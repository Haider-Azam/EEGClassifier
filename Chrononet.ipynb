{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not install, you could not use those pipelines\n"
     ]
    }
   ],
   "source": [
    "#/********************************************\n",
    "#* Author: Rahat Ul Ain \n",
    "#* Based on chrononet implementation by Kunal Patel\n",
    "#* location: https://github.com/kunalpatel1793/Neural-Nets-Final-Project\n",
    "#********************************************/\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import braindecode \n",
    "import torch\n",
    "from torch import nn\n",
    "from skorch.callbacks import Checkpoint\n",
    "from skorch.dataset import Dataset\n",
    "from skorch.helper import predefined_split\n",
    "import math\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Chrono_config\n",
    "def readDatafromPath(path,windows=1):\n",
    "\tmatrix= np.empty((15000, 22), dtype='f')\n",
    "\tfor file in os.listdir(path):\n",
    "\t\tif '.edf' in file:\n",
    "\t\t\tf=os.path.join(path, file)\n",
    "\t\t\ttry:\n",
    "\t\t\t\tedf_file = mne.io.read_raw_edf(f,  eog = ['FP1', 'FP2', 'F3', 'F4',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'C3', 'C4',  'P3', 'P4','O1', 'O2','F7', 'F8',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'T3', 'T4', 'T5', 'T6','PZ','FZ', 'CZ','A1', 'A2'], verbose='error')\n",
    "\t\t\t\t#print(f)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tedf_file_down_sampled = edf_file.resample(250, npad = \"auto\")# set sampling frequency to 250 Hz\n",
    "\t\t\ted = edf_file_down_sampled.to_data_frame(picks = None, index = None, time_format = None, scalings = None,\n",
    "\t\t\tcopy = True, start = None, stop = None)# converting into dataframe\n",
    "\t\t\tFp1_Fp7 = (ed.loc[: , 'FP1']) - (ed.loc[: , 'F7'])\n",
    "\t\t\tFP2_F8 = (ed.loc[: , 'FP2']) - (ed.loc[: , 'F8'])\n",
    "\t\t\tF7_T3 = (ed.loc[: , 'F7']) - (ed.loc[: , 'T3'])\n",
    "\t\t\tF8_T4 = (ed.loc[: , 'F8']) - (ed.loc[: , 'T4'])\n",
    "\t\t\tT3_T5 = (ed.loc[: , 'T3']) - (ed.loc[: , 'T5'])\n",
    "\t\t\tT4_T6 = (ed.loc[: , 'T4']) - (ed.loc[: , 'T6'])\n",
    "\t\t\tT5_O1 = (ed.loc[: , 'T5']) - (ed.loc[: , 'O1'])\n",
    "\t\t\tT6_O2 = (ed.loc[: , 'T6']) - (ed.loc[: , 'O2'])\n",
    "\t\t\tA1_T3 = (ed.loc[: , 'A1']) - (ed.loc[: , 'T3'])\n",
    "\t\t\tT4_A2 = (ed.loc[: , 'T4']) - (ed.loc[: , 'A2'])\n",
    "\t\t\tT3_C3 = (ed.loc[: , 'T3']) - (ed.loc[: , 'C3'])\n",
    "\t\t\tC4_T4 = (ed.loc[: , 'C4']) - (ed.loc[: , 'T4'])\n",
    "\t\t\tC3_CZ = (ed.loc[: , 'C3']) - (ed.loc[: , 'CZ'])\n",
    "\t\t\tCZ_C4 = (ed.loc[: , 'CZ']) - (ed.loc[: , 'C4'])\n",
    "\t\t\tFP1_F3 = (ed.loc[: , 'FP1']) - (ed.loc[: , 'F3'])\n",
    "\t\t\tFP2_F4 = (ed.loc[: , 'FP2']) - (ed.loc[: , 'F4'])\n",
    "\t\t\tF3_C3 = (ed.loc[: , 'F3']) - (ed.loc[: , 'C3'])\n",
    "\t\t\tF4_C4 = (ed.loc[: , 'F4']) - (ed.loc[: , 'C4'])\n",
    "\t\t\tC3_P3 = (ed.loc[: , 'C3']) - (ed.loc[: , 'P3'])\n",
    "\t\t\tC4_P4 = (ed.loc[: , 'C4']) - (ed.loc[: , 'P4'])\n",
    "\t\t\tP3_O1 = (ed.loc[: , 'P3']) - (ed.loc[: , 'O1'])\n",
    "\t\t\tP4_O2 = (ed.loc[: , 'P4']) - (ed.loc[: , 'O2'])\n",
    "\t\t\tdata = {\n",
    "\t\t\t'Fp1_Fp7': Fp1_Fp7,\n",
    "\t\t\t'FP2_F8': FP2_F8,\n",
    "\t\t\t'F7_T3': F7_T3,\n",
    "\t\t\t'F8_T4': F8_T4,\n",
    "\t\t\t'T3_T5': T3_T5,\n",
    "\t\t\t'T4_T6': T4_T6,\n",
    "\t\t\t'T5_O1': T5_O1,\n",
    "\t\t\t'T6_O2': T6_O2,\n",
    "\t\t\t'A1_T3': A1_T3,\n",
    "\t\t\t'T4_A2': T4_A2,\n",
    "\t\t\t'T3_C3': T3_C3,\n",
    "\t\t\t'C4_T4': C4_T4,\n",
    "\t\t\t'C3_CZ': C3_CZ,\n",
    "\t\t\t'CZ_C4': CZ_C4,\n",
    "\t\t\t'FP1_F3': FP1_F3,\n",
    "\t\t\t'FP2_F4': FP2_F4,\n",
    "\t\t\t'F3_C3': F3_C3,\n",
    "\t\t\t'F4_C4': F4_C4,\n",
    "\t\t\t'C3_P3': C3_P3,\n",
    "\t\t\t'C4_P4': C4_P4,\n",
    "\t\t\t'P3_O1': P3_O1,\n",
    "\t\t\t'P4_O2': P4_O2\n",
    "\t\t\t}\n",
    "\t\t\tnew_data_frame = pd.DataFrame(data, columns = ['Fp1_Fp7', 'FP2_F8', 'F7_T3', 'F8_T4', 'T3_T5', 'T4_T6', 'T5_O1', 'T6_O2', 'A1_T3', 'T4_A2', 'T3_C3', 'C4_T4', 'C3_CZ',\n",
    "\t\t\t'CZ_C4', 'FP1_F3', 'FP2_F4', 'F3_C3', 'F4_C4', 'C3_P3', 'C4_P4', 'P3_O1', 'P4_O2'\n",
    "\t\t\t])\n",
    "\t\t\tfs = edf_file_down_sampled.info['sfreq']\n",
    "\t\t\t[row, col] = new_data_frame.shape\n",
    "\t\t\tn = math.ceil(row / (15000 - (fs * 5)))\n",
    "\t\t\ti = 0\n",
    "\t\t\tj = 15000\n",
    "\t\t\t#print(f\"row:{row},n:{n}\")\n",
    "\n",
    "\t\t\tfor y in range(n - 1):\n",
    "\n",
    "\t\t\t\t#print(f\"i:{i},j:{j},y:{y}\")\n",
    "\t\t\t\tif y>windows:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\telif y == 0 and j < row:\n",
    "\t\t\t\t\texample_1 = new_data_frame[0: 15000]\n",
    "\t\t\t\t\tmatrix=np.dstack((matrix,example_1.to_numpy()))\n",
    "\t\t\t\telif j < row:\n",
    "\t\t\t\t\texample = new_data_frame[i: j]\n",
    "\t\t\t\t\tmatrix = np.dstack((matrix, example.to_numpy()))\n",
    "\t\t\t\telse :\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\texample = new_data_frame[-15000: ]\n",
    "\t\t\t\t\t\tmatrix = np.dstack((matrix, example.to_numpy()))\n",
    "\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\tpass\n",
    "\t\t\t\t\tfinally:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t#Goes to next window with 5 seconds of overlap\n",
    "\t\t\t\ti = int(j - (fs * 5))\n",
    "\t\t\t\tj = int(j + 15000 - (fs * 5))\n",
    "\t\t\t#print(f\"shape:{matrix.shape}\")\n",
    "\tmatrix=matrix[:,:,1:]\n",
    "\treturn matrix.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Chrono_config\n",
    "import scipy\n",
    "print('starting')\n",
    "normal_train = readDatafromPath(path = Chrono_config.normaldir)\n",
    "normal_train_dim = normal_train.shape[-1]\n",
    "# print(\"normal original dim\")\n",
    "# print(normal_train_dim)\n",
    "normal_train_zeros = np.zeros(normal_train_dim)\n",
    "# print(\"zeros array dim\")\n",
    "# print(normal_train_zeros)\n",
    "abnormal_train = readDatafromPath(path = Chrono_config.abnormaldir)\n",
    "abnormal_train_dim = abnormal_train.shape[-1]\n",
    "#print(abnormal_train_dim)\n",
    "abnormal_train_ones = np.ones(abnormal_train_dim)\n",
    "#print(abnormal_train_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.dstack((normal_train, abnormal_train))\n",
    "train_label = np.append(normal_train_zeros, abnormal_train_ones)\n",
    "\n",
    "train_data = np.swapaxes(train_data,0,2)\n",
    "\n",
    "bs,t,f = train_data.shape\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(train_data.dtype)\n",
    "print(train_label.dtype)\n",
    "#enc_labels = to_categorical(train_label, num_classes=2)              \n",
    "#train_label= enc_labels\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(train_data.dtype)\n",
    "print(train_label.dtype)\n",
    "print('training labels have been loaded')\n",
    "mid=len(train_label)//2\n",
    "scipy.io.savemat(\"D:/chrono_train_1.mat\",{\"x\":train_data[:mid,:,:],\"y\":train_label[:mid]})\n",
    "scipy.io.savemat(\"D:/chrono_train_2.mat\",{\"x\":train_data[mid:,:,:],\"y\":train_label[mid:]})\n",
    "del normal_train,normal_train_dim,normal_train_zeros,abnormal_train,abnormal_train_dim,abnormal_train_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Chrono_config\n",
    "import scipy\n",
    "print('starting')\n",
    "normal_eval = readDatafromPath(path = Chrono_config.eval_normaldir,windows=8)\n",
    "normal_eval_dim = normal_eval.shape[-1]\n",
    "# print(\"normal original dim\")\n",
    "# print(normal_eval_dim)\n",
    "normal_eval_zeros = np.zeros(normal_eval_dim)\n",
    "# print(\"zeros array dim\")\n",
    "# print(normal_eval_zeros)\n",
    "\n",
    "abnormal_eval = readDatafromPath(path = Chrono_config.eval_abnormaldir,windows=8)\n",
    "abnormal_eval_dim = abnormal_eval.shape[-1]\n",
    "#print(abnormal_eval_dim)\n",
    "abnormal_eval_ones = np.ones(abnormal_eval_dim)\n",
    "#print(abnormal_eval_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = np.dstack((normal_eval, abnormal_eval))\n",
    "eval_label = np.append(normal_eval_zeros, abnormal_eval_ones)\n",
    "\n",
    "eval_data = np.swapaxes(eval_data,0,2)\n",
    "\n",
    "bs,t,f = eval_data.shape\n",
    "scipy.io.savemat(\"D:/chrono_eval.mat\",{\"x\":eval_data,\"y\":eval_label})\n",
    "#enc_labels = to_categorical(eval_label, num_classes=2)\n",
    "#eval_label= enc_labels\n",
    "del normal_eval,normal_eval_dim,normal_eval_zeros,abnormal_eval,abnormal_eval_dim,abnormal_eval_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "inputs=scipy.io.loadmat(\"D:/chrono_train_1.mat\")\n",
    "train_data=inputs[\"x\"]\n",
    "train_label=inputs[\"y\"].squeeze()\n",
    "inputs=scipy.io.loadmat(\"D:/chrono_train_2.mat\")\n",
    "train_data=np.concatenate((train_data,inputs[\"x\"]),axis=0)\n",
    "train_label=np.concatenate((train_label,inputs[\"y\"].squeeze()),axis=0)\n",
    "train_label=train_label\n",
    "bs,t,f = train_data.shape\n",
    "inputs=scipy.io.loadmat(\"D:/chrono_eval.mat\")\n",
    "eval_data=inputs[\"x\"]\n",
    "eval_label=inputs[\"y\"].squeeze()\n",
    "del inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_train_data=train_data[train_label==1]\n",
    "abnormal_train_label=train_label[train_label==1]\n",
    "train_data=train_data[train_label==0]\n",
    "train_label=train_label[train_label==0]\n",
    "\n",
    "quotient=len(train_label)//len(abnormal_train_label)\n",
    "remainder=len(train_label)/len(abnormal_train_label)-quotient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_label=abnormal_train_label\n",
    "duplicated_data=abnormal_train_data\n",
    "remainder_length=int(remainder*len(abnormal_train_label))\n",
    "for i in range(quotient-1):\n",
    "    duplicated_label=np.concatenate([duplicated_label,abnormal_train_label],axis=0)\n",
    "    duplicated_data=np.concatenate([duplicated_data,abnormal_train_data],axis=0)\n",
    "duplicated_label=np.concatenate([duplicated_label,abnormal_train_label[:remainder_length]],axis=0)\n",
    "duplicated_data=np.concatenate([duplicated_data,abnormal_train_data[:remainder_length]],axis=0)\n",
    "del abnormal_train_data,abnormal_train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=np.concatenate([train_data,duplicated_data],axis=0)\n",
    "train_label=np.concatenate([train_label,duplicated_label],axis=0)\n",
    "del duplicated_data,duplicated_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names=['A1', 'A2', 'C3', 'C4', 'CZ', 'F3', 'F4', 'F7', 'F8', 'FP1','FP2', 'FZ', 'O1', 'O2','P3', 'P4', 'PZ', 'T3', 'T4', 'T5', 'T6']\n",
    "picked_ch=[0,1,2,3,18,17]\n",
    "train_x=train_data[:,picked_ch]\n",
    "t=len(picked_ch)\n",
    "eval_x=eval_data[:,picked_ch]\n",
    "print(f'Channels chosen:{[ch_names[ch] for ch in picked_ch]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CausalConv1d(in_channels, out_channels, kernel_size, dilation=1, **kwargs):\n",
    "   pad = (kernel_size - 1) * dilation\n",
    "   return torch.nn.Conv1d(in_channels, out_channels, kernel_size, padding=pad, dilation=dilation, **kwargs)\n",
    "class Inception_Block(torch.nn.Module):\n",
    "  def __init__(self,t=32,out_channels=32,pad=0):\n",
    "    super().__init__()\n",
    "    self.tower1= CausalConv1d(in_channels=t,out_channels=32,kernel_size=2,stride=2)\n",
    "    self.tower2= CausalConv1d(in_channels=t,out_channels=32,kernel_size=4,stride=2)\n",
    "    self.tower3= CausalConv1d(in_channels=t,out_channels=32,kernel_size=8,stride=2)\n",
    "    self.bnorm=nn.BatchNorm1d(32)\n",
    "    self.relu=nn.ReLU()\n",
    "    self.dropout = nn.Dropout1d(0.45)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    t1=self.tower1(inputs)\n",
    "    t1=t1[:, :, :-1]\n",
    "    t1=self.relu(t1)\n",
    "    t1=self.bnorm(t1)\n",
    "\n",
    "    t2=self.tower2(inputs)\n",
    "    t2=t2[:, :, :-2]\n",
    "    t2=self.relu(t2)\n",
    "    t2=self.bnorm(t2)\n",
    "\n",
    "    t3=self.tower3(inputs)\n",
    "    t3=t3[:, :, :-4]\n",
    "    t3=self.relu(t3)\n",
    "    t3=self.bnorm(t3)\n",
    "\n",
    "    output=torch.cat([t1,t2,t3],dim=1)\n",
    "    output=self.dropout(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "input_shape = (4, t, f)\n",
    "x = tf.random.normal(input_shape)\n",
    "\n",
    "tower1 = tf.keras.layers.Conv1D(32, 2, strides=2,activation='relu',padding=\"causal\")(x)\n",
    "print(tower1.shape)\n",
    "tower2 = tf.keras.layers.Conv1D(32, 4, strides=2,activation='relu',padding=\"causal\")(x)\n",
    "print(tower2.shape)\n",
    "tower3 = tf.keras.layers.Conv1D(32, 8, strides=2,activation='relu',padding=\"causal\")(x)\n",
    "print(tower3.shape)\n",
    "a=torch.rand(size=(4, t, f))\n",
    "tower4=CausalConv1d(in_channels=f,out_channels=32,kernel_size=2,stride=2)(a.mT)[:, :, :-1].mT\n",
    "print(tower4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronoNet(torch.nn.Module):\n",
    "  def __init__(self,t=32,out_channels=32):\n",
    "    super().__init__()\n",
    "    self.block1= Inception_Block(t,out_channels)\n",
    "    self.block2= Inception_Block(96,out_channels,pad=1)\n",
    "    self.block3= Inception_Block(96,out_channels)\n",
    "    self.gru1=nn.GRU(input_size=96,hidden_size=32,batch_first=True)\n",
    "    self.gru2=nn.GRU(input_size=32,hidden_size=32,batch_first=True)\n",
    "    self.gru3=nn.GRU(input_size=64,hidden_size=32,batch_first=True)\n",
    "    self.gru4=nn.GRU(input_size=96,hidden_size=32,batch_first=True)\n",
    "    self.tanh=nn.Tanh()\n",
    "    self.classifier = nn.Linear(32,2)\n",
    "    self.softmax=nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "\n",
    "    b1=self.block1(inputs.mT)\n",
    "\n",
    "    b2=self.block2(b1)\n",
    "\n",
    "    b3=self.block3(b2)\n",
    "\n",
    "    res1,_=self.gru1(b3.mT)\n",
    "    res1=self.tanh(res1)\n",
    "    res2,_=self.gru2(res1)\n",
    "    res2=self.tanh(res2)\n",
    "    res1_2=torch.cat([res1,res2],dim=2)\n",
    "    res3,_=self.gru3(res1_2)\n",
    "    res3=self.tanh(res3)\n",
    "    x=torch.cat([res1,res2,res3],dim=2)\n",
    "    x,_=self.gru4(x)\n",
    "    x=self.tanh(x)\n",
    "    if x.dim()==2:\n",
    "      x=x[-1,:]\n",
    "    elif x.dim()==3:\n",
    "      x=x[:,-1,:]\n",
    "    output=self.classifier(x)\n",
    "    output=self.softmax(output)\n",
    "    return output\n",
    "#Causal conv1d difficult, causal padding is left padding of dilation_rate*(kernel_size-1) where rate is 1\n",
    "#Will have to define a class in order to make chrononet\n",
    "model=ChronoNet(t=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(size=(3,22,15000))\n",
    "out=model.forward(a)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
       "  module_=ChronoNet(\n",
       "    (block1): Inception_Block(\n",
       "      (tower1): Conv1d(15000, 32, kernel_size=(2,), stride=(2,), padding=(1,))\n",
       "      (tower2): Conv1d(15000, 32, kernel_size=(4,), stride=(2,), padding=(3,))\n",
       "      (tower3): Conv1d(15000, 32, kernel_size=(8,), stride=(2,), padding=(7,))\n",
       "      (bnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout1d(p=0.45, inplace=False)\n",
       "    )\n",
       "    (block2): Inception_Block(\n",
       "      (tower1): Conv1d(96, 32, kernel_size=(2,), stride=(2,), padding=(1,))\n",
       "      (tower2): Conv1d(96, 32, kernel_size=(4,), stride=(2,), padding=(3,))\n",
       "      (tower3): Conv1d(96, 32, kernel_size=(8,), stride=(2,), padding=(7,))\n",
       "      (bnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout1d(p=0.45, inplace=False)\n",
       "    )\n",
       "    (block3): Inception_Block(\n",
       "      (tower1): Conv1d(96, 32, kernel_size=(2,), stride=(2,), padding=(1,))\n",
       "      (tower2): Conv1d(96, 32, kernel_size=(4,), stride=(2,), padding=(3,))\n",
       "      (tower3): Conv1d(96, 32, kernel_size=(8,), stride=(2,), padding=(7,))\n",
       "      (bnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout1d(p=0.45, inplace=False)\n",
       "    )\n",
       "    (gru1): GRU(96, 32, batch_first=True)\n",
       "    (gru2): GRU(32, 32, batch_first=True)\n",
       "    (gru3): GRU(64, 32, batch_first=True)\n",
       "    (gru4): GRU(96, 32, batch_first=True)\n",
       "    (tanh): Tanh()\n",
       "    (classifier): Linear(in_features=32, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor = lambda net: any(net.history[-1, ('valid_accuracy_best','valid_f1_best','valid_loss_best')])\n",
    "cp=Checkpoint(monitor='valid_f1_best',dirname='model',f_params='ChronoNetbest_param.pkl',f_optimizer='ChronoNetbest_opt.pkl',\n",
    "              f_history='ChronoNetbest_history.json')\n",
    "classifier = braindecode.EEGClassifier(\n",
    "        model,\n",
    "        criterion=nn.CrossEntropyLoss(),\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        train_split=predefined_split(Dataset(eval_data,eval_label)),\n",
    "        optimizer__lr=3e-4,\n",
    "        iterator_train__shuffle=True,\n",
    "        batch_size=16,\n",
    "        device=\"cuda\",\n",
    "        callbacks=[\"accuracy\",\"f1\",'roc_auc',cp],\n",
    "        warm_start=True,\n",
    "        )\n",
    "classifier.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.load_params(\n",
    "        f_params=f'model/ChronoNetbest_param.pkl', f_optimizer=f'model/ChronoNetbest_opt.pkl', f_history=f'model/ChronoNetbest_history.json')\n",
    "print(\"Paramters Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_f1    train_loss    train_roc_auc    valid_acc    valid_accuracy    valid_f1    valid_loss    valid_roc_auc    cp      dur\n",
      "-------  ----------------  ----------  ------------  ---------------  -----------  ----------------  ----------  ------------  ---------------  ----  -------\n",
      "      1            \u001b[36m0.6826\u001b[0m      \u001b[32m0.6172\u001b[0m        \u001b[35m0.6637\u001b[0m           \u001b[31m0.7623\u001b[0m       \u001b[94m0.6043\u001b[0m            \u001b[36m0.6043\u001b[0m      \u001b[32m0.4643\u001b[0m        \u001b[35m0.6747\u001b[0m           \u001b[31m0.6699\u001b[0m     +  82.8431\n",
      "      2            \u001b[36m0.7846\u001b[0m      \u001b[32m0.7574\u001b[0m        \u001b[35m0.6055\u001b[0m           \u001b[31m0.8655\u001b[0m       0.6011            0.6011      0.4464        0.6919           0.6537        70.9360\n",
      "      3            \u001b[36m0.8354\u001b[0m      \u001b[32m0.8194\u001b[0m        \u001b[35m0.5392\u001b[0m           \u001b[31m0.9011\u001b[0m       0.5854            0.5854      0.4211        0.7117           0.6316        69.7820\n",
      "      4            \u001b[36m0.8677\u001b[0m      \u001b[32m0.8596\u001b[0m        \u001b[35m0.5039\u001b[0m           \u001b[31m0.9263\u001b[0m       0.5879            0.5879      0.4335        0.7206           0.6119        72.5681\n",
      "      5            \u001b[36m0.8906\u001b[0m      \u001b[32m0.8866\u001b[0m        \u001b[35m0.4826\u001b[0m           0.9203       0.5942            0.5942      \u001b[32m0.4714\u001b[0m        0.7128           0.6440     +  71.7910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
       "  module_=ChronoNet(\n",
       "    (block1): Inception_Block(\n",
       "      (tower1): Conv1d(15000, 32, kernel_size=(2,), stride=(2,), padding=(1,))\n",
       "      (tower2): Conv1d(15000, 32, kernel_size=(4,), stride=(2,), padding=(3,))\n",
       "      (tower3): Conv1d(15000, 32, kernel_size=(8,), stride=(2,), padding=(7,))\n",
       "      (bnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout1d(p=0.45, inplace=False)\n",
       "    )\n",
       "    (block2): Inception_Block(\n",
       "      (tower1): Conv1d(96, 32, kernel_size=(2,), stride=(2,), padding=(1,))\n",
       "      (tower2): Conv1d(96, 32, kernel_size=(4,), stride=(2,), padding=(3,))\n",
       "      (tower3): Conv1d(96, 32, kernel_size=(8,), stride=(2,), padding=(7,))\n",
       "      (bnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout1d(p=0.45, inplace=False)\n",
       "    )\n",
       "    (block3): Inception_Block(\n",
       "      (tower1): Conv1d(96, 32, kernel_size=(2,), stride=(2,), padding=(1,))\n",
       "      (tower2): Conv1d(96, 32, kernel_size=(4,), stride=(2,), padding=(3,))\n",
       "      (tower3): Conv1d(96, 32, kernel_size=(8,), stride=(2,), padding=(7,))\n",
       "      (bnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout1d(p=0.45, inplace=False)\n",
       "    )\n",
       "    (gru1): GRU(96, 32, batch_first=True)\n",
       "    (gru2): GRU(32, 32, batch_first=True)\n",
       "    (gru3): GRU(64, 32, batch_first=True)\n",
       "    (gru4): GRU(96, 32, batch_first=True)\n",
       "    (tanh): Tanh()\n",
       "    (classifier): Linear(in_features=32, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_data,train_label,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(eval_data,eval_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels=classifier.predict(eval_data)\n",
    "accuracy=np.mean(predicted_labels==eval_label)\n",
    "print(f\"Accuracy:{accuracy}\")\n",
    "tp=np.sum(predicted_labels*eval_label)\n",
    "precision=tp/np.sum(predicted_labels)\n",
    "recall=tp/np.sum(eval_label)\n",
    "f1=2*precision*recall/(precision+recall)\n",
    "print(f\"F1-Score:{f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
