{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not install, you could not use those pipelines\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import elu,relu,leaky_relu\n",
    "import braindecode\n",
    "from braindecode.models import *\n",
    "from braindecode.models.functions import squeeze_final_output,square,safe_log\n",
    "from skorch.dataset import Dataset\n",
    "from skorch.callbacks import Checkpoint\n",
    "from skorch.helper import predefined_split\n",
    "from config import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from mne import set_log_level\n",
    "set_log_level(False)\n",
    "device = 'cuda' if cuda else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads preprocessed data from mat files\n",
    "import scipy\n",
    "import numpy as np\n",
    "inputs=scipy.io.loadmat(\"E:/train_set_1.mat\")\n",
    "X=inputs[\"x\"]\n",
    "y=inputs[\"y\"].squeeze()\n",
    "\n",
    "inputs=scipy.io.loadmat(\"E:/train_set_2.mat\")\n",
    "X=np.concatenate((X,inputs[\"x\"]),axis=0)\n",
    "y=np.concatenate((y,inputs[\"y\"].squeeze()),axis=0)\n",
    "input_time_length=X.shape[-1]\n",
    "inputs=scipy.io.loadmat(\"E:/test_set.mat\")\n",
    "test_x=inputs[\"x\"]\n",
    "test_y=inputs[\"y\"].squeeze()\n",
    "del inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels chosen:['T6']\n"
     ]
    }
   ],
   "source": [
    "#We will now train the model by taking pairs or combinations of channels and passing their entire length.\n",
    "ch_names=['A1', 'A2', 'C3', 'C4', 'CZ', 'F3', 'F4', 'F7', 'F8', 'FP1','FP2', 'FZ', 'O1', 'O2','P3', 'P4', 'PZ', 'T3', 'T4', 'T5', 'T6']\n",
    "picked_ch=[20]\n",
    "input_time_length=X.shape[-1]\n",
    "train_x=X[:,picked_ch]\n",
    "n_chans=len(picked_ch)\n",
    "eval_x=test_x[:,picked_ch]\n",
    "print(f'Channels chosen:{[ch_names[ch] for ch in picked_ch]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will convert the 1d array into a 2d matrix by converting from (1,60000) to (10,6000) and then passing them through the network\n",
    "#Due to conv_time_spat layer in model, it would be better to have it so that first 10 entries are in channel 1, next 10 in channel 2 etc\n",
    "#So that channel 1 will have 10,110,210 entries and so on\n",
    "n_chans=10\n",
    "input_time_length=input_time_length//n_chans\n",
    "train_x=train_x.reshape(len(train_x),n_chans,input_time_length,order='F')\n",
    "eval_x=eval_x.reshape(len(eval_x),n_chans,input_time_length,order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='shallow_deep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shallow_deep\n",
      "============================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "============================================================================================================================================\n",
      "Deep4Net (Deep4Net)                      [1, 10, 6000]             [1, 2]                    --                        --\n",
      "├─Ensure4d (ensuredims): 1-1             [1, 10, 6000]             [1, 10, 6000, 1]          --                        --\n",
      "├─Rearrange (dimshuffle): 1-2            [1, 10, 6000, 1]          [1, 1, 6000, 10]          --                        --\n",
      "├─CombinedConv (conv_time_spat): 1-3     [1, 1, 6000, 10]          [1, 32, 5976, 1]          11,072                    --\n",
      "├─BatchNorm2d (bnorm): 1-4               [1, 32, 5976, 1]          [1, 32, 5976, 1]          64                        --\n",
      "├─Expression (conv_nonlin): 1-5          [1, 32, 5976, 1]          [1, 32, 5976, 1]          --                        --\n",
      "├─AvgPool2dWithConv (pool): 1-6          [1, 32, 5976, 1]          [1, 32, 1988, 1]          --                        [15, 1]\n",
      "├─Expression (pool_nonlin): 1-7          [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
      "├─Dropout (drop_2): 1-8                  [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
      "├─Conv2d (conv_2): 1-9                   [1, 32, 1988, 1]          [1, 53, 1977, 1]          20,352                    [12, 1]\n",
      "├─BatchNorm2d (bnorm_2): 1-10            [1, 53, 1977, 1]          [1, 53, 1977, 1]          106                       --\n",
      "├─Expression (nonlin_2): 1-11            [1, 53, 1977, 1]          [1, 53, 1977, 1]          --                        --\n",
      "├─AvgPool2dWithConv (pool_2): 1-12       [1, 53, 1977, 1]          [1, 53, 655, 1]           --                        [15, 1]\n",
      "├─Expression (pool_nonlin_2): 1-13       [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
      "├─Dropout (drop_3): 1-14                 [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
      "├─Conv2d (conv_3): 1-15                  [1, 53, 655, 1]           [1, 90, 642, 1]           66,780                    [14, 1]\n",
      "├─BatchNorm2d (bnorm_3): 1-16            [1, 90, 642, 1]           [1, 90, 642, 1]           180                       --\n",
      "├─Expression (nonlin_3): 1-17            [1, 90, 642, 1]           [1, 90, 642, 1]           --                        --\n",
      "├─AvgPool2dWithConv (pool_3): 1-18       [1, 90, 642, 1]           [1, 90, 210, 1]           --                        [15, 1]\n",
      "├─Expression (pool_nonlin_3): 1-19       [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
      "├─Dropout (drop_4): 1-20                 [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
      "├─Conv2d (conv_4): 1-21                  [1, 90, 210, 1]           [1, 151, 179, 1]          434,880                   [32, 1]\n",
      "├─BatchNorm2d (bnorm_4): 1-22            [1, 151, 179, 1]          [1, 151, 179, 1]          302                       --\n",
      "├─Expression (nonlin_4): 1-23            [1, 151, 179, 1]          [1, 151, 179, 1]          --                        --\n",
      "├─AvgPool2dWithConv (pool_4): 1-24       [1, 151, 179, 1]          [1, 151, 55, 1]           --                        [15, 1]\n",
      "├─Expression (pool_nonlin_4): 1-25       [1, 151, 55, 1]           [1, 151, 55, 1]           --                        --\n",
      "├─Sequential (final_layer): 1-26         [1, 151, 55, 1]           [1, 2]                    --                        --\n",
      "│    └─Conv2d (conv_classifier): 2-1     [1, 151, 55, 1]           [1, 2, 1, 1]              16,612                    [55, 1]\n",
      "│    └─LogSoftmax (logsoftmax): 2-2      [1, 2, 1, 1]              [1, 2, 1, 1]              --                        --\n",
      "│    └─Expression (squeeze): 2-3         [1, 2, 1, 1]              [1, 2]                    --                        --\n",
      "============================================================================================================================================\n",
      "Total params: 550,348\n",
      "Trainable params: 550,348\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 160.97\n",
      "============================================================================================================================================\n",
      "Input size (MB): 0.24\n",
      "Forward/backward pass size (MB): 4.56\n",
      "Params size (MB): 2.16\n",
      "Estimated Total Size (MB): 6.96\n",
      "============================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "criterion=torch.nn.NLLLoss\n",
    "if model_name==\"shallow\":\n",
    "    optimizer_lr = 0.0000625\n",
    "    optimizer_weight_decay = 0\n",
    "    pool_time_length=150\n",
    "    pool_time_stride=50\n",
    "    #The final conv length is auto to ensure that output will give two values for single EEG window\n",
    "    model = ShallowFBCSPNet(n_chans,\n",
    "                                    n_classes,\n",
    "                                    n_filters_time=n_start_chans,\n",
    "                                    n_filters_spat=n_start_chans,\n",
    "                                    input_window_samples=input_time_length,\n",
    "                                    pool_time_length=pool_time_length,\n",
    "                                    pool_time_stride=pool_time_stride,\n",
    "                                    final_conv_length='auto',)\n",
    "    test=torch.ones(size=(7,n_chans,input_time_length))\n",
    "    out=model.forward(test)\n",
    "    print(out.shape)\n",
    "    del test,out\n",
    "elif model_name==\"deep\":\n",
    "    optimizer_lr = init_lr\n",
    "    optimizer_weight_decay = 0\n",
    "    model = Deep4Net(n_chans, n_classes,\n",
    "                         n_filters_time=n_start_chans,\n",
    "                         n_filters_spat=n_start_chans,\n",
    "                         input_window_samples=input_time_length,\n",
    "                         n_filters_2 = int(n_start_chans * n_chan_factor),\n",
    "                         n_filters_3 = int(n_start_chans * (n_chan_factor ** 2.0)),\n",
    "                         n_filters_4 = int(n_start_chans * (n_chan_factor ** 3.0)),\n",
    "                         final_conv_length='auto',\n",
    "                        stride_before_pool=True)\n",
    "    test=torch.ones(size=(7,n_chans,input_time_length))\n",
    "    out=model.forward(test)\n",
    "    print(out.shape)\n",
    "    del test,out\n",
    "elif model_name==\"deep_smac\" or model_name == 'deep_smac_bnorm':\n",
    "    optimizer_lr = 0.0000625\n",
    "    if model_name == 'deep_smac':\n",
    "            do_batch_norm = False\n",
    "    else:\n",
    "        do_batch_norm = True\n",
    "    drop_prob = 0.244445\n",
    "    filter_length_2 = 12\n",
    "    filter_length_3 = 24\n",
    "    filter_length_4 = 36\n",
    "    filter_time_length = 21\n",
    "    #final_conv_length = 1\n",
    "    first_nonlin = elu\n",
    "    first_pool_mode = 'mean'\n",
    "    later_nonlin = elu\n",
    "    later_pool_mode = 'mean'\n",
    "    n_filters_factor = 1.679066\n",
    "    n_filters_start = 32\n",
    "    pool_time_length = 3\n",
    "    pool_time_stride = 3\n",
    "    split_first_layer = True\n",
    "    n_chan_factor = n_filters_factor\n",
    "    n_start_chans = n_filters_start\n",
    "    model = Deep4Net(n_chans, n_classes,\n",
    "            n_filters_time=n_start_chans,\n",
    "            n_filters_spat=n_start_chans,\n",
    "            input_window_samples=input_time_length,\n",
    "            n_filters_2=int(n_start_chans * n_chan_factor),\n",
    "            n_filters_3=int(n_start_chans * (n_chan_factor ** 2.0)),\n",
    "            n_filters_4=int(n_start_chans * (n_chan_factor ** 3.0)),\n",
    "            final_conv_length='auto',\n",
    "            batch_norm=do_batch_norm,\n",
    "            drop_prob=drop_prob,\n",
    "            filter_length_2=filter_length_2,\n",
    "            filter_length_3=filter_length_3,\n",
    "            filter_length_4=filter_length_4,\n",
    "            filter_time_length=filter_time_length,\n",
    "            first_conv_nonlin=first_nonlin,\n",
    "            first_pool_mode=first_pool_mode,\n",
    "            later_conv_nonlin=later_nonlin,\n",
    "            later_pool_mode=later_pool_mode,\n",
    "            #pool_time_length=pool_time_length,\n",
    "            #pool_time_stride=pool_time_stride,\n",
    "            split_first_layer=split_first_layer,\n",
    "            stride_before_pool=True)\n",
    "elif model_name==\"shallow_deep\":\n",
    "    drop_prob = 0.244445\n",
    "    filter_length_2 = 12\n",
    "    filter_length_3 = 14\n",
    "    filter_length_4 = 32\n",
    "    n_filters_factor = 1.679066\n",
    "    n_filters_start = 32\n",
    "    split_first_layer = True\n",
    "    n_chan_factor = n_filters_factor\n",
    "    n_start_chans = n_filters_start\n",
    "\n",
    "    optimizer_lr = 0.0000625\n",
    "    optimizer_weight_decay = 0\n",
    "    conv_time_length=25\n",
    "    first_conv_nonlin=relu\n",
    "    first_pool_nonlin=safe_log\n",
    "    later_conv_nonlin=elu\n",
    "    later_pool_nonlin=safe_log\n",
    "    first_pool_mode = 'mean'\n",
    "    later_pool_mode = 'mean'\n",
    "    pool_time_length=15\n",
    "    model = Deep4Net(n_chans, n_classes,\n",
    "                            input_time_length,\n",
    "                            n_filters_time=n_start_chans,\n",
    "                            n_filters_spat=n_start_chans,\n",
    "                            n_filters_2 = int(n_start_chans * n_chan_factor),\n",
    "                            n_filters_3 = int(n_start_chans * (n_chan_factor ** 2.0)),\n",
    "                            n_filters_4 = int(n_start_chans * (n_chan_factor ** 3.0)),\n",
    "                            final_conv_length='auto',\n",
    "                            first_pool_nonlin=first_pool_nonlin,\n",
    "                            first_conv_nonlin=first_conv_nonlin,\n",
    "                            #later_pool_nonlin=later_pool_nonlin,\n",
    "                            #later_conv_nonlin=later_conv_nonlin,\n",
    "                            filter_time_length=conv_time_length,\n",
    "                            pool_time_length=pool_time_length,\n",
    "                            first_pool_mode=first_pool_mode,\n",
    "                            later_pool_mode=later_pool_mode,\n",
    "                            split_first_layer=split_first_layer,\n",
    "                            drop_prob=drop_prob,\n",
    "                            filter_length_2=filter_length_2,\n",
    "                            filter_length_3=filter_length_3,\n",
    "                            filter_length_4=filter_length_4,\n",
    "                            )\n",
    "elif model_name==\"attention\":\n",
    "    optimizer_lr = 0.0000625\n",
    "    optimizer_weight_decay = 0\n",
    "    model=ATCNet(n_chans,n_classes,input_time_length//sampling_freq,sampling_freq,concat=True,tcn_depth=4)\n",
    "    test=torch.ones(size=(7,n_chans,input_time_length))\n",
    "    out=model.forward(test)\n",
    "    print(out.shape)\n",
    "    del test,out\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "print(model_name)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
       "  module_=============================================================================================================================================\n",
       "  Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "  ============================================================================================================================================\n",
       "  Deep4Net (Deep4Net)                      [1, 10, 6000]             [1, 2]                    --                        --\n",
       "  ├─Ensure4d (ensuredims): 1-1             [1, 10, 6000]             [1, 10, 6000, 1]          --                        --\n",
       "  ├─Rearrange (dimshuffle): 1-2            [1, 10, 6000, 1]          [1, 1, 6000, 10]          --                        --\n",
       "  ├─CombinedConv (conv_time_spat): 1-3     [1, 1, 6000, 10]          [1, 32, 5976, 1]          11,072                    --\n",
       "  ├─BatchNorm2d (bnorm): 1-4               [1, 32, 5976, 1]          [1, 32, 5976, 1]          64                        --\n",
       "  ├─Expression (conv_nonlin): 1-5          [1, 32, 5976, 1]          [1, 32, 5976, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool): 1-6          [1, 32, 5976, 1]          [1, 32, 1988, 1]          --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin): 1-7          [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
       "  ├─Dropout (drop_2): 1-8                  [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
       "  ├─Conv2d (conv_2): 1-9                   [1, 32, 1988, 1]          [1, 53, 1977, 1]          20,352                    [12, 1]\n",
       "  ├─BatchNorm2d (bnorm_2): 1-10            [1, 53, 1977, 1]          [1, 53, 1977, 1]          106                       --\n",
       "  ├─Expression (nonlin_2): 1-11            [1, 53, 1977, 1]          [1, 53, 1977, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool_2): 1-12       [1, 53, 1977, 1]          [1, 53, 655, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_2): 1-13       [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
       "  ├─Dropout (drop_3): 1-14                 [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
       "  ├─Conv2d (conv_3): 1-15                  [1, 53, 655, 1]           [1, 90, 642, 1]           66,780                    [14, 1]\n",
       "  ├─BatchNorm2d (bnorm_3): 1-16            [1, 90, 642, 1]           [1, 90, 642, 1]           180                       --\n",
       "  ├─Expression (nonlin_3): 1-17            [1, 90, 642, 1]           [1, 90, 642, 1]           --                        --\n",
       "  ├─AvgPool2dWithConv (pool_3): 1-18       [1, 90, 642, 1]           [1, 90, 210, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_3): 1-19       [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
       "  ├─Dropout (drop_4): 1-20                 [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
       "  ├─Conv2d (conv_4): 1-21                  [1, 90, 210, 1]           [1, 151, 179, 1]          434,880                   [32, 1]\n",
       "  ├─BatchNorm2d (bnorm_4): 1-22            [1, 151, 179, 1]          [1, 151, 179, 1]          302                       --\n",
       "  ├─Expression (nonlin_4): 1-23            [1, 151, 179, 1]          [1, 151, 179, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool_4): 1-24       [1, 151, 179, 1]          [1, 151, 55, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_4): 1-25       [1, 151, 55, 1]           [1, 151, 55, 1]           --                        --\n",
       "  ├─Sequential (final_layer): 1-26         [1, 151, 55, 1]           [1, 2]                    --                        --\n",
       "  │    └─Conv2d (conv_classifier): 2-1     [1, 151, 55, 1]           [1, 2, 1, 1]              16,612                    [55, 1]\n",
       "  │    └─LogSoftmax (logsoftmax): 2-2      [1, 2, 1, 1]              [1, 2, 1, 1]              --                        --\n",
       "  │    └─Expression (squeeze): 2-3         [1, 2, 1, 1]              [1, 2]                    --                        --\n",
       "  ============================================================================================================================================\n",
       "  Total params: 550,348\n",
       "  Trainable params: 550,348\n",
       "  Non-trainable params: 0\n",
       "  Total mult-adds (M): 160.97\n",
       "  ============================================================================================================================================\n",
       "  Input size (MB): 0.24\n",
       "  Forward/backward pass size (MB): 4.56\n",
       "  Params size (MB): 2.16\n",
       "  Estimated Total Size (MB): 6.96\n",
       "  ============================================================================================================================================,\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor = lambda net: any(net.history[-1, ('valid_accuracy_best','valid_f1_best','valid_loss_best')])\n",
    "cp=Checkpoint(monitor='valid_f1_best',dirname='model',f_params=f'chanbest_param.pkl',\n",
    "               f_optimizer=f'chanbest_opt.pkl', f_history=f'chanbest_history.json')\n",
    "classifier = braindecode.EEGClassifier(\n",
    "    model,\n",
    "    criterion=criterion,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=predefined_split(Dataset(eval_x,test_y)),\n",
    "    optimizer__lr=optimizer_lr,\n",
    "    #optimizer__weight_decay=optimizer_weight_decay,\n",
    "    iterator_train__shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    "    callbacks=[\"accuracy\",\"f1\",'roc_auc',cp],#Try (\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=20))\n",
    "    warm_start=True,\n",
    "    )\n",
    "classifier.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Accuracy    F1-score       Loss              AUC\n",
    "#A1:0.7481      0.7344        0.5478           0.8070\n",
    "#A2:0.7556      0.7130        0.6907           0.7879\n",
    "#C3:0.7259      0.7040        0.6569           0.7496\n",
    "#C4:0.7111      0.6286        0.8119           0.7738\n",
    "#CZ:0.7259      0.6942        0.7168           0.7628\n",
    "#F3:0.7111      0.6549        0.8018           0.7540\n",
    "#F4:0.7111      0.6422        0.6267           0.7608\n",
    "#F7:0.7556      0.6733        0.6990           0.8015\n",
    "#F8:0.7333      0.6897        0.6086           0.7520\n",
    "#FP1:0.7259     0.7259        0.5895           0.7788\n",
    "#FP2:0.7481     0.7167        0.6900           0.7705\n",
    "#FZ:0.7852      0.7521        0.6720           0.8140   #Consistently high results\n",
    "#O1:0.7556      0.7130        0.5564           0.8158\n",
    "#O2:0.7185      0.6415        0.7401           0.7711\n",
    "#P3:0.7037      0.6154        0.5774           0.8110\n",
    "#P4:0.7407      0.7445        0.5793           0.7993\n",
    "#PZ:0.7037      0.6825        0.6528           0.7238\n",
    "#T3:0.7704      0.7395        0.4957           0.8506\n",
    "#T4:0.7185      0.7286        0.5802           0.7753\n",
    "#T5:0.7481      0.6909        0.5537           0.8239\n",
    "#T6:0.7185      0.6607        0.5840           0.7722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_f1    train_loss    train_roc_auc    valid_acc    valid_accuracy    valid_f1    valid_loss    valid_roc_auc    cp     dur\n",
      "-------  ----------------  ----------  ------------  ---------------  -----------  ----------------  ----------  ------------  ---------------  ----  ------\n",
      "      1            \u001b[36m0.8359\u001b[0m      \u001b[32m0.0000\u001b[0m        \u001b[35m0.5263\u001b[0m           \u001b[31m0.7272\u001b[0m       \u001b[94m0.5259\u001b[0m            \u001b[36m0.5259\u001b[0m      \u001b[32m0.0000\u001b[0m        \u001b[35m2.0995\u001b[0m           \u001b[31m0.6791\u001b[0m     +  3.2420\n",
      "      2            0.7533      \u001b[32m0.0636\u001b[0m        \u001b[35m0.3956\u001b[0m           0.2904       0.5259            0.5259      \u001b[32m0.1351\u001b[0m        \u001b[35m1.3070\u001b[0m           0.2890     +  3.0460\n",
      "      3            \u001b[36m0.8431\u001b[0m      \u001b[32m0.0966\u001b[0m        \u001b[35m0.3772\u001b[0m           0.6548       \u001b[94m0.5407\u001b[0m            \u001b[36m0.5407\u001b[0m      0.0606        \u001b[35m1.2865\u001b[0m           \u001b[31m0.6901\u001b[0m        2.8390\n",
      "      4            \u001b[36m0.8599\u001b[0m      \u001b[32m0.4031\u001b[0m        \u001b[35m0.3595\u001b[0m           \u001b[31m0.8334\u001b[0m       \u001b[94m0.6296\u001b[0m            \u001b[36m0.6296\u001b[0m      \u001b[32m0.3902\u001b[0m        \u001b[35m0.7604\u001b[0m           \u001b[31m0.8156\u001b[0m     +  2.7831\n",
      "      5            0.8048      \u001b[32m0.4512\u001b[0m        \u001b[35m0.3566\u001b[0m           0.8020       \u001b[94m0.7111\u001b[0m            \u001b[36m0.7111\u001b[0m      \u001b[32m0.6139\u001b[0m        1.2069           0.7698     +  2.7950\n",
      "      6            0.8503      0.1987        0.3662           \u001b[31m0.8465\u001b[0m       0.5630            0.5630      0.1449        0.8797           0.7885        2.7790\n",
      "      7            \u001b[36m0.8671\u001b[0m      0.4278        0.3595           \u001b[31m0.8623\u001b[0m       0.6444            0.6444      0.4146        0.7795           \u001b[31m0.8319\u001b[0m        2.7740\n",
      "      8            0.8509      \u001b[32m0.4929\u001b[0m        \u001b[35m0.3425\u001b[0m           0.8501       0.6889            0.6889      0.5625        0.7749           \u001b[31m0.8325\u001b[0m        2.7620\n",
      "      9            \u001b[36m0.8743\u001b[0m      0.4167        \u001b[35m0.3379\u001b[0m           \u001b[31m0.8757\u001b[0m       0.6074            0.6074      0.2933        \u001b[35m0.7232\u001b[0m           \u001b[31m0.8523\u001b[0m        2.7810\n",
      "     10            \u001b[36m0.8784\u001b[0m      \u001b[32m0.5519\u001b[0m        \u001b[35m0.3209\u001b[0m           0.8617       0.6667            0.6667      0.4944        0.7922           0.7986        2.8300\n",
      "     11            0.8719      0.4831        0.3239           \u001b[31m0.8776\u001b[0m       0.6667            0.6667      0.4944        0.7915           0.8330        2.7910\n",
      "     12            0.8743      0.5374        0.3257           \u001b[31m0.8858\u001b[0m       0.6963            0.6963      0.5591        \u001b[35m0.6510\u001b[0m           0.8360        2.7940\n",
      "     13            \u001b[36m0.8904\u001b[0m      \u001b[32m0.6065\u001b[0m        \u001b[35m0.3070\u001b[0m           \u001b[31m0.8948\u001b[0m       0.6593            0.6593      0.4889        \u001b[35m0.6357\u001b[0m           0.8288        2.8270\n",
      "     14            0.8850      0.5596        \u001b[35m0.3066\u001b[0m           \u001b[31m0.8997\u001b[0m       0.6519            0.6519      0.4471        0.6801           0.8440        2.8150\n",
      "     15            0.8671      0.5647        \u001b[35m0.3039\u001b[0m           0.8738       0.6889            0.6889      0.5625        0.8343           0.8338        2.8390\n",
      "     16            0.8868      0.5379        0.3085           \u001b[31m0.9011\u001b[0m       0.6667            0.6667      0.4578        0.7836           0.8451        2.8050\n",
      "     17            0.8671      0.3393        \u001b[35m0.2937\u001b[0m           0.8859       0.6000            0.6000      0.2703        0.8834           0.8123        2.7970\n",
      "     18            0.8868      0.5310        0.3014           \u001b[31m0.9055\u001b[0m       0.6444            0.6444      0.4146        0.7694           0.8092        2.7670\n",
      "     19            0.8671      0.5919        \u001b[35m0.2922\u001b[0m           0.8685       0.6963            0.6963      0.5859        1.0021           0.7927        2.7880\n",
      "     20            0.8838      0.5488        0.3004           \u001b[31m0.9096\u001b[0m       0.7037            0.7037      0.5652        0.7146           0.8493        2.8280\n",
      "     21            0.8886      0.5441        0.2936           \u001b[31m0.9119\u001b[0m       0.6815            0.6815      0.4941        0.7566           0.8116        2.8060\n",
      "     22            \u001b[36m0.8940\u001b[0m      \u001b[32m0.6093\u001b[0m        \u001b[35m0.2760\u001b[0m           0.9107       0.6815            0.6815      0.5057        0.6975           0.7960        2.7900\n",
      "     23            \u001b[36m0.9090\u001b[0m      \u001b[32m0.7043\u001b[0m        0.2760           \u001b[31m0.9304\u001b[0m       \u001b[94m0.7259\u001b[0m            \u001b[36m0.7259\u001b[0m      \u001b[32m0.6186\u001b[0m        \u001b[35m0.6122\u001b[0m           0.8387     +  2.7610\n",
      "     24            0.9078      0.6695        \u001b[35m0.2740\u001b[0m           0.9302       0.6815            0.6815      0.5057        0.6819           0.8147        2.7740\n",
      "     25            0.8940      0.6811        \u001b[35m0.2623\u001b[0m           0.9190       0.7111            0.7111      0.6061        \u001b[35m0.6043\u001b[0m           0.8154        2.7860\n",
      "     26            0.8952      0.5803        0.2666           0.9220       0.6815            0.6815      0.4941        0.8379           0.7892        2.8010\n",
      "     27            0.8886      0.5529        0.2684           0.9201       0.6593            0.6593      0.4651        1.0248           0.8299        2.7680\n",
      "     28            0.9006      0.6261        \u001b[35m0.2605\u001b[0m           0.9199       0.6667            0.6667      0.4944        0.9410           0.8270        2.7690\n",
      "     29            0.8916      0.6189        \u001b[35m0.2497\u001b[0m           0.9121       0.6889            0.6889      0.5227        0.7874           0.7573        2.8000\n",
      "     30            \u001b[36m0.9228\u001b[0m      \u001b[32m0.7362\u001b[0m        0.2732           \u001b[31m0.9485\u001b[0m       0.6593            0.6593      0.4651        0.7917           0.8083        2.7840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
       "  module_=============================================================================================================================================\n",
       "  Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "  ============================================================================================================================================\n",
       "  Deep4Net (Deep4Net)                      [1, 10, 6000]             [1, 2]                    --                        --\n",
       "  ├─Ensure4d (ensuredims): 1-1             [1, 10, 6000]             [1, 10, 6000, 1]          --                        --\n",
       "  ├─Rearrange (dimshuffle): 1-2            [1, 10, 6000, 1]          [1, 1, 6000, 10]          --                        --\n",
       "  ├─CombinedConv (conv_time_spat): 1-3     [1, 1, 6000, 10]          [1, 32, 5976, 1]          11,072                    --\n",
       "  ├─BatchNorm2d (bnorm): 1-4               [1, 32, 5976, 1]          [1, 32, 5976, 1]          64                        --\n",
       "  ├─Expression (conv_nonlin): 1-5          [1, 32, 5976, 1]          [1, 32, 5976, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool): 1-6          [1, 32, 5976, 1]          [1, 32, 1988, 1]          --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin): 1-7          [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
       "  ├─Dropout (drop_2): 1-8                  [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
       "  ├─Conv2d (conv_2): 1-9                   [1, 32, 1988, 1]          [1, 53, 1977, 1]          20,352                    [12, 1]\n",
       "  ├─BatchNorm2d (bnorm_2): 1-10            [1, 53, 1977, 1]          [1, 53, 1977, 1]          106                       --\n",
       "  ├─Expression (nonlin_2): 1-11            [1, 53, 1977, 1]          [1, 53, 1977, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool_2): 1-12       [1, 53, 1977, 1]          [1, 53, 655, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_2): 1-13       [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
       "  ├─Dropout (drop_3): 1-14                 [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
       "  ├─Conv2d (conv_3): 1-15                  [1, 53, 655, 1]           [1, 90, 642, 1]           66,780                    [14, 1]\n",
       "  ├─BatchNorm2d (bnorm_3): 1-16            [1, 90, 642, 1]           [1, 90, 642, 1]           180                       --\n",
       "  ├─Expression (nonlin_3): 1-17            [1, 90, 642, 1]           [1, 90, 642, 1]           --                        --\n",
       "  ├─AvgPool2dWithConv (pool_3): 1-18       [1, 90, 642, 1]           [1, 90, 210, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_3): 1-19       [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
       "  ├─Dropout (drop_4): 1-20                 [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
       "  ├─Conv2d (conv_4): 1-21                  [1, 90, 210, 1]           [1, 151, 179, 1]          434,880                   [32, 1]\n",
       "  ├─BatchNorm2d (bnorm_4): 1-22            [1, 151, 179, 1]          [1, 151, 179, 1]          302                       --\n",
       "  ├─Expression (nonlin_4): 1-23            [1, 151, 179, 1]          [1, 151, 179, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool_4): 1-24       [1, 151, 179, 1]          [1, 151, 55, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_4): 1-25       [1, 151, 55, 1]           [1, 151, 55, 1]           --                        --\n",
       "  ├─Sequential (final_layer): 1-26         [1, 151, 55, 1]           [1, 2]                    --                        --\n",
       "  │    └─Conv2d (conv_classifier): 2-1     [1, 151, 55, 1]           [1, 2, 1, 1]              16,612                    [55, 1]\n",
       "  │    └─LogSoftmax (logsoftmax): 2-2      [1, 2, 1, 1]              [1, 2, 1, 1]              --                        --\n",
       "  │    └─Expression (squeeze): 2-3         [1, 2, 1, 1]              [1, 2]                    --                        --\n",
       "  ============================================================================================================================================\n",
       "  Total params: 550,348\n",
       "  Trainable params: 550,348\n",
       "  Non-trainable params: 0\n",
       "  Total mult-adds (M): 160.97\n",
       "  ============================================================================================================================================\n",
       "  Input size (MB): 0.24\n",
       "  Forward/backward pass size (MB): 4.56\n",
       "  Params size (MB): 2.16\n",
       "  Estimated Total Size (MB): 6.96\n",
       "  ============================================================================================================================================,\n",
       ")"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_x,y,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save_params(f_params=f'model/chanbest_param.pkl',f_optimizer=f'model/chanbest_opt.pkl', f_history=f'model/chanbest_history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.load_params(f_params=f'model/chanbest_param.pkl',f_optimizer=f'model/chanbest_opt.pkl', f_history=f'model/chanbest_history.json')\n",
    "print(\"Paramters Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block finds the accuracy, f1 score and roc auc of the valid/test set\n",
    "pred_labels=classifier.predict(eval_x)\n",
    "auc=roc_auc_score(test_y,classifier.predict_proba(eval_x)[:,1])\n",
    "accuracy=np.mean(pred_labels==test_y)\n",
    "tp=np.sum(pred_labels*test_y)\n",
    "precision=tp/np.sum(pred_labels)\n",
    "recall=tp/np.sum(test_y)\n",
    "f1=2*precision*recall/(precision+recall)\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Accuracy:{accuracy}\")\n",
    "print(f\"F1-Score:{f1}\")\n",
    "print(f\"roc_auc score:{auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
