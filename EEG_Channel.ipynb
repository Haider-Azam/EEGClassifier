{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not install, you could not use those pipelines\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import elu,relu,leaky_relu\n",
    "import braindecode\n",
    "from braindecode.models import *\n",
    "from braindecode.models.functions import squeeze_final_output,square,safe_log\n",
    "from skorch.dataset import Dataset\n",
    "from skorch.callbacks import Checkpoint\n",
    "from skorch.helper import predefined_split\n",
    "from config import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from mne import set_log_level\n",
    "set_log_level(False)\n",
    "device = 'cuda' if cuda else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads preprocessed data from mat files\n",
    "import scipy\n",
    "import numpy as np\n",
    "inputs=scipy.io.loadmat(\"E:/train_set_1.mat\")\n",
    "X=inputs[\"x\"]\n",
    "y=inputs[\"y\"].squeeze()\n",
    "\n",
    "inputs=scipy.io.loadmat(\"E:/train_set_2.mat\")\n",
    "X=np.concatenate((X,inputs[\"x\"]),axis=0)\n",
    "y=np.concatenate((y,inputs[\"y\"].squeeze()),axis=0)\n",
    "input_time_length=X.shape[-1]\n",
    "inputs=scipy.io.loadmat(\"E:/test_set.mat\")\n",
    "test_x=inputs[\"x\"]\n",
    "test_y=inputs[\"y\"].squeeze()\n",
    "del inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels chosen:['C3']\n"
     ]
    }
   ],
   "source": [
    "#We will now train the model by taking pairs or combinations of channels and passing their entire length.\n",
    "ch_names=['A1', 'A2', 'C3', 'C4', 'CZ', 'F3', 'F4', 'F7', 'F8', 'FP1','FP2', 'FZ', 'O1', 'O2','P3', 'P4', 'PZ', 'T3', 'T4', 'T5', 'T6']\n",
    "picked_ch=[2]\n",
    "input_time_length=X.shape[-1]\n",
    "train_x=X[:,picked_ch]\n",
    "n_chans=len(picked_ch)\n",
    "eval_x=test_x[:,picked_ch]\n",
    "print(f'Channels chosen:{[ch_names[ch] for ch in picked_ch]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will convert the 1d array into a 2d matrix by converting from (1,60000) to (10,6000) and then passing them through the network\n",
    "#Due to conv_time_spat layer in model, it would be better to have it so that first 10 entries are in channel 1, next 10 in channel 2 etc\n",
    "#So that channel 1 will have 10,110,210 entries and so on\n",
    "n_chans=10\n",
    "input_time_length=input_time_length//n_chans\n",
    "train_x=train_x.reshape(len(train_x),n_chans,input_time_length)\n",
    "eval_x=eval_x.reshape(len(eval_x),n_chans,input_time_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='shallow_deep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shallow_deep\n",
      "============================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "============================================================================================================================================\n",
      "Deep4Net (Deep4Net)                      [1, 10, 6000]             [1, 2]                    --                        --\n",
      "├─Ensure4d (ensuredims): 1-1             [1, 10, 6000]             [1, 10, 6000, 1]          --                        --\n",
      "├─Rearrange (dimshuffle): 1-2            [1, 10, 6000, 1]          [1, 1, 6000, 10]          --                        --\n",
      "├─CombinedConv (conv_time_spat): 1-3     [1, 1, 6000, 10]          [1, 32, 5976, 1]          11,072                    --\n",
      "├─BatchNorm2d (bnorm): 1-4               [1, 32, 5976, 1]          [1, 32, 5976, 1]          64                        --\n",
      "├─Expression (conv_nonlin): 1-5          [1, 32, 5976, 1]          [1, 32, 5976, 1]          --                        --\n",
      "├─AvgPool2dWithConv (pool): 1-6          [1, 32, 5976, 1]          [1, 32, 1988, 1]          --                        [15, 1]\n",
      "├─Expression (pool_nonlin): 1-7          [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
      "├─Dropout (drop_2): 1-8                  [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
      "├─Conv2d (conv_2): 1-9                   [1, 32, 1988, 1]          [1, 53, 1977, 1]          20,352                    [12, 1]\n",
      "├─BatchNorm2d (bnorm_2): 1-10            [1, 53, 1977, 1]          [1, 53, 1977, 1]          106                       --\n",
      "├─Expression (nonlin_2): 1-11            [1, 53, 1977, 1]          [1, 53, 1977, 1]          --                        --\n",
      "├─AvgPool2dWithConv (pool_2): 1-12       [1, 53, 1977, 1]          [1, 53, 655, 1]           --                        [15, 1]\n",
      "├─Expression (pool_nonlin_2): 1-13       [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
      "├─Dropout (drop_3): 1-14                 [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
      "├─Conv2d (conv_3): 1-15                  [1, 53, 655, 1]           [1, 90, 642, 1]           66,780                    [14, 1]\n",
      "├─BatchNorm2d (bnorm_3): 1-16            [1, 90, 642, 1]           [1, 90, 642, 1]           180                       --\n",
      "├─Expression (nonlin_3): 1-17            [1, 90, 642, 1]           [1, 90, 642, 1]           --                        --\n",
      "├─AvgPool2dWithConv (pool_3): 1-18       [1, 90, 642, 1]           [1, 90, 210, 1]           --                        [15, 1]\n",
      "├─Expression (pool_nonlin_3): 1-19       [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
      "├─Dropout (drop_4): 1-20                 [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
      "├─Conv2d (conv_4): 1-21                  [1, 90, 210, 1]           [1, 151, 179, 1]          434,880                   [32, 1]\n",
      "├─BatchNorm2d (bnorm_4): 1-22            [1, 151, 179, 1]          [1, 151, 179, 1]          302                       --\n",
      "├─Expression (nonlin_4): 1-23            [1, 151, 179, 1]          [1, 151, 179, 1]          --                        --\n",
      "├─AvgPool2dWithConv (pool_4): 1-24       [1, 151, 179, 1]          [1, 151, 55, 1]           --                        [15, 1]\n",
      "├─Expression (pool_nonlin_4): 1-25       [1, 151, 55, 1]           [1, 151, 55, 1]           --                        --\n",
      "├─Sequential (final_layer): 1-26         [1, 151, 55, 1]           [1, 2]                    --                        --\n",
      "│    └─Conv2d (conv_classifier): 2-1     [1, 151, 55, 1]           [1, 2, 1, 1]              16,612                    [55, 1]\n",
      "│    └─LogSoftmax (logsoftmax): 2-2      [1, 2, 1, 1]              [1, 2, 1, 1]              --                        --\n",
      "│    └─Expression (squeeze): 2-3         [1, 2, 1, 1]              [1, 2]                    --                        --\n",
      "============================================================================================================================================\n",
      "Total params: 550,348\n",
      "Trainable params: 550,348\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 160.97\n",
      "============================================================================================================================================\n",
      "Input size (MB): 0.24\n",
      "Forward/backward pass size (MB): 4.56\n",
      "Params size (MB): 2.16\n",
      "Estimated Total Size (MB): 6.96\n",
      "============================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "criterion=torch.nn.NLLLoss\n",
    "if model_name==\"shallow\":\n",
    "    optimizer_lr = 0.0000625\n",
    "    optimizer_weight_decay = 0\n",
    "    pool_time_length=150\n",
    "    pool_time_stride=50\n",
    "    #The final conv length is auto to ensure that output will give two values for single EEG window\n",
    "    model = ShallowFBCSPNet(n_chans,\n",
    "                                    n_classes,\n",
    "                                    n_filters_time=n_start_chans,\n",
    "                                    n_filters_spat=n_start_chans,\n",
    "                                    input_window_samples=input_time_length,\n",
    "                                    pool_time_length=pool_time_length,\n",
    "                                    pool_time_stride=pool_time_stride,\n",
    "                                    final_conv_length='auto',)\n",
    "    test=torch.ones(size=(7,n_chans,input_time_length))\n",
    "    out=model.forward(test)\n",
    "    print(out.shape)\n",
    "    del test,out\n",
    "elif model_name==\"deep\":\n",
    "    optimizer_lr = init_lr\n",
    "    optimizer_weight_decay = 0\n",
    "    model = Deep4Net(n_chans, n_classes,\n",
    "                         n_filters_time=n_start_chans,\n",
    "                         n_filters_spat=n_start_chans,\n",
    "                         input_window_samples=input_time_length,\n",
    "                         n_filters_2 = int(n_start_chans * n_chan_factor),\n",
    "                         n_filters_3 = int(n_start_chans * (n_chan_factor ** 2.0)),\n",
    "                         n_filters_4 = int(n_start_chans * (n_chan_factor ** 3.0)),\n",
    "                         final_conv_length='auto',\n",
    "                        stride_before_pool=True)\n",
    "    test=torch.ones(size=(7,n_chans,input_time_length))\n",
    "    out=model.forward(test)\n",
    "    print(out.shape)\n",
    "    del test,out\n",
    "elif model_name==\"deep_smac\" or model_name == 'deep_smac_bnorm':\n",
    "    optimizer_lr = 0.0000625\n",
    "    if model_name == 'deep_smac':\n",
    "            do_batch_norm = False\n",
    "    else:\n",
    "        do_batch_norm = True\n",
    "    drop_prob = 0.244445\n",
    "    filter_length_2 = 12\n",
    "    filter_length_3 = 24\n",
    "    filter_length_4 = 36\n",
    "    filter_time_length = 21\n",
    "    #final_conv_length = 1\n",
    "    first_nonlin = elu\n",
    "    first_pool_mode = 'mean'\n",
    "    later_nonlin = elu\n",
    "    later_pool_mode = 'mean'\n",
    "    n_filters_factor = 1.679066\n",
    "    n_filters_start = 32\n",
    "    pool_time_length = 3\n",
    "    pool_time_stride = 3\n",
    "    split_first_layer = True\n",
    "    n_chan_factor = n_filters_factor\n",
    "    n_start_chans = n_filters_start\n",
    "    model = Deep4Net(n_chans, n_classes,\n",
    "            n_filters_time=n_start_chans,\n",
    "            n_filters_spat=n_start_chans,\n",
    "            input_window_samples=input_time_length,\n",
    "            n_filters_2=int(n_start_chans * n_chan_factor),\n",
    "            n_filters_3=int(n_start_chans * (n_chan_factor ** 2.0)),\n",
    "            n_filters_4=int(n_start_chans * (n_chan_factor ** 3.0)),\n",
    "            final_conv_length='auto',\n",
    "            batch_norm=do_batch_norm,\n",
    "            drop_prob=drop_prob,\n",
    "            filter_length_2=filter_length_2,\n",
    "            filter_length_3=filter_length_3,\n",
    "            filter_length_4=filter_length_4,\n",
    "            filter_time_length=filter_time_length,\n",
    "            first_conv_nonlin=first_nonlin,\n",
    "            first_pool_mode=first_pool_mode,\n",
    "            later_conv_nonlin=later_nonlin,\n",
    "            later_pool_mode=later_pool_mode,\n",
    "            #pool_time_length=pool_time_length,\n",
    "            #pool_time_stride=pool_time_stride,\n",
    "            split_first_layer=split_first_layer,\n",
    "            stride_before_pool=True)\n",
    "elif model_name==\"shallow_deep\":\n",
    "    drop_prob = 0.244445\n",
    "    filter_length_2 = 12\n",
    "    filter_length_3 = 14\n",
    "    filter_length_4 = 32\n",
    "    n_filters_factor = 1.679066\n",
    "    n_filters_start = 32\n",
    "    split_first_layer = True\n",
    "    n_chan_factor = n_filters_factor\n",
    "    n_start_chans = n_filters_start\n",
    "\n",
    "    optimizer_lr = 0.0000625\n",
    "    optimizer_weight_decay = 0\n",
    "    conv_time_length=25\n",
    "    first_conv_nonlin=relu\n",
    "    first_pool_nonlin=safe_log\n",
    "    later_conv_nonlin=elu\n",
    "    later_pool_nonlin=safe_log\n",
    "    first_pool_mode = 'mean'\n",
    "    later_pool_mode = 'mean'\n",
    "    pool_time_length=15\n",
    "    model = Deep4Net(n_chans, n_classes,\n",
    "                            input_time_length,\n",
    "                            n_filters_time=n_start_chans,\n",
    "                            n_filters_spat=n_start_chans,\n",
    "                            n_filters_2 = int(n_start_chans * n_chan_factor),\n",
    "                            n_filters_3 = int(n_start_chans * (n_chan_factor ** 2.0)),\n",
    "                            n_filters_4 = int(n_start_chans * (n_chan_factor ** 3.0)),\n",
    "                            final_conv_length='auto',\n",
    "                            first_pool_nonlin=first_pool_nonlin,\n",
    "                            first_conv_nonlin=first_conv_nonlin,\n",
    "                            #later_pool_nonlin=later_pool_nonlin,\n",
    "                            #later_conv_nonlin=later_conv_nonlin,\n",
    "                            filter_time_length=conv_time_length,\n",
    "                            pool_time_length=pool_time_length,\n",
    "                            first_pool_mode=first_pool_mode,\n",
    "                            later_pool_mode=later_pool_mode,\n",
    "                            split_first_layer=split_first_layer,\n",
    "                            drop_prob=drop_prob,\n",
    "                            filter_length_2=filter_length_2,\n",
    "                            filter_length_3=filter_length_3,\n",
    "                            filter_length_4=filter_length_4,\n",
    "                            )\n",
    "elif model_name==\"attention\":\n",
    "    optimizer_lr = 0.0000625\n",
    "    optimizer_weight_decay = 0\n",
    "    model=ATCNet(n_chans,n_classes,input_time_length//sampling_freq,sampling_freq,concat=True,tcn_depth=4)\n",
    "    test=torch.ones(size=(7,n_chans,input_time_length))\n",
    "    out=model.forward(test)\n",
    "    print(out.shape)\n",
    "    del test,out\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "print(model_name)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
       "  module_=============================================================================================================================================\n",
       "  Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "  ============================================================================================================================================\n",
       "  Deep4Net (Deep4Net)                      [1, 10, 6000]             [1, 2]                    --                        --\n",
       "  ├─Ensure4d (ensuredims): 1-1             [1, 10, 6000]             [1, 10, 6000, 1]          --                        --\n",
       "  ├─Rearrange (dimshuffle): 1-2            [1, 10, 6000, 1]          [1, 1, 6000, 10]          --                        --\n",
       "  ├─CombinedConv (conv_time_spat): 1-3     [1, 1, 6000, 10]          [1, 32, 5976, 1]          11,072                    --\n",
       "  ├─BatchNorm2d (bnorm): 1-4               [1, 32, 5976, 1]          [1, 32, 5976, 1]          64                        --\n",
       "  ├─Expression (conv_nonlin): 1-5          [1, 32, 5976, 1]          [1, 32, 5976, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool): 1-6          [1, 32, 5976, 1]          [1, 32, 1988, 1]          --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin): 1-7          [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
       "  ├─Dropout (drop_2): 1-8                  [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
       "  ├─Conv2d (conv_2): 1-9                   [1, 32, 1988, 1]          [1, 53, 1977, 1]          20,352                    [12, 1]\n",
       "  ├─BatchNorm2d (bnorm_2): 1-10            [1, 53, 1977, 1]          [1, 53, 1977, 1]          106                       --\n",
       "  ├─Expression (nonlin_2): 1-11            [1, 53, 1977, 1]          [1, 53, 1977, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool_2): 1-12       [1, 53, 1977, 1]          [1, 53, 655, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_2): 1-13       [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
       "  ├─Dropout (drop_3): 1-14                 [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
       "  ├─Conv2d (conv_3): 1-15                  [1, 53, 655, 1]           [1, 90, 642, 1]           66,780                    [14, 1]\n",
       "  ├─BatchNorm2d (bnorm_3): 1-16            [1, 90, 642, 1]           [1, 90, 642, 1]           180                       --\n",
       "  ├─Expression (nonlin_3): 1-17            [1, 90, 642, 1]           [1, 90, 642, 1]           --                        --\n",
       "  ├─AvgPool2dWithConv (pool_3): 1-18       [1, 90, 642, 1]           [1, 90, 210, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_3): 1-19       [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
       "  ├─Dropout (drop_4): 1-20                 [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
       "  ├─Conv2d (conv_4): 1-21                  [1, 90, 210, 1]           [1, 151, 179, 1]          434,880                   [32, 1]\n",
       "  ├─BatchNorm2d (bnorm_4): 1-22            [1, 151, 179, 1]          [1, 151, 179, 1]          302                       --\n",
       "  ├─Expression (nonlin_4): 1-23            [1, 151, 179, 1]          [1, 151, 179, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool_4): 1-24       [1, 151, 179, 1]          [1, 151, 55, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_4): 1-25       [1, 151, 55, 1]           [1, 151, 55, 1]           --                        --\n",
       "  ├─Sequential (final_layer): 1-26         [1, 151, 55, 1]           [1, 2]                    --                        --\n",
       "  │    └─Conv2d (conv_classifier): 2-1     [1, 151, 55, 1]           [1, 2, 1, 1]              16,612                    [55, 1]\n",
       "  │    └─LogSoftmax (logsoftmax): 2-2      [1, 2, 1, 1]              [1, 2, 1, 1]              --                        --\n",
       "  │    └─Expression (squeeze): 2-3         [1, 2, 1, 1]              [1, 2]                    --                        --\n",
       "  ============================================================================================================================================\n",
       "  Total params: 550,348\n",
       "  Trainable params: 550,348\n",
       "  Non-trainable params: 0\n",
       "  Total mult-adds (M): 160.97\n",
       "  ============================================================================================================================================\n",
       "  Input size (MB): 0.24\n",
       "  Forward/backward pass size (MB): 4.56\n",
       "  Params size (MB): 2.16\n",
       "  Estimated Total Size (MB): 6.96\n",
       "  ============================================================================================================================================,\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor = lambda net: any(net.history[-1, ('valid_accuracy_best','valid_f1_best','valid_loss_best')])\n",
    "cp=Checkpoint(monitor='valid_f1_best',dirname='model',f_params=f'chanbest_param.pkl',\n",
    "               f_optimizer=f'chanbest_opt.pkl', f_history=f'chanbest_history.json')\n",
    "classifier = braindecode.EEGClassifier(\n",
    "    model,\n",
    "    criterion=criterion,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=predefined_split(Dataset(eval_x,test_y)),\n",
    "    optimizer__lr=optimizer_lr,\n",
    "    #optimizer__weight_decay=optimizer_weight_decay,\n",
    "    iterator_train__shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    "    callbacks=[\"accuracy\",\"f1\",'roc_auc',cp],#Try (\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=20))\n",
    "    warm_start=True,\n",
    "    )\n",
    "classifier.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.load_params(f_params=f'model/chanbest_param.pkl',f_optimizer=f'model/chanbest_opt.pkl', f_history=f'model/chanbest_history.json')\n",
    "print(\"Paramters Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "test=np.random.rand(7,n_chans,input_time_length)\n",
    "out=classifier.predict(test)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Accuracy    F1-score\n",
    "A1:0.7630      0.6735\n",
    "C3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_f1    train_loss    train_roc_auc    valid_acc    valid_accuracy    valid_f1    valid_loss    valid_roc_auc    cp     dur\n",
      "-------  ----------------  ----------  ------------  ---------------  -----------  ----------------  ----------  ------------  ---------------  ----  ------\n",
      "      1            \u001b[36m0.1641\u001b[0m      \u001b[32m0.2819\u001b[0m        \u001b[35m0.5372\u001b[0m           \u001b[31m0.3474\u001b[0m       \u001b[94m0.4741\u001b[0m            \u001b[36m0.4741\u001b[0m      \u001b[32m0.6432\u001b[0m        \u001b[35m1.6220\u001b[0m           \u001b[31m0.3002\u001b[0m     +  2.8870\n",
      "      2            \u001b[36m0.5485\u001b[0m      0.1962        \u001b[35m0.3798\u001b[0m           \u001b[31m0.4185\u001b[0m       \u001b[94m0.4889\u001b[0m            \u001b[36m0.4889\u001b[0m      0.4000        \u001b[35m1.1271\u001b[0m           \u001b[31m0.4580\u001b[0m        2.8530\n",
      "      3            \u001b[36m0.8030\u001b[0m      0.2034        \u001b[35m0.3430\u001b[0m           \u001b[31m0.5956\u001b[0m       \u001b[94m0.5704\u001b[0m            \u001b[36m0.5704\u001b[0m      0.2927        1.2108           \u001b[31m0.6052\u001b[0m        2.8940\n",
      "      4            \u001b[36m0.8641\u001b[0m      \u001b[32m0.3914\u001b[0m        \u001b[35m0.3304\u001b[0m           \u001b[31m0.8576\u001b[0m       \u001b[94m0.6000\u001b[0m            \u001b[36m0.6000\u001b[0m      0.3077        1.2030           \u001b[31m0.7892\u001b[0m        2.8440\n",
      "      5            \u001b[36m0.8778\u001b[0m      \u001b[32m0.4796\u001b[0m        \u001b[35m0.3207\u001b[0m           \u001b[31m0.8829\u001b[0m       \u001b[94m0.6074\u001b[0m            \u001b[36m0.6074\u001b[0m      0.3614        \u001b[35m0.8957\u001b[0m           \u001b[31m0.7951\u001b[0m        2.7190\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(train_x,y,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save_params(f_params=f'model/chanbest_param.pkl',f_optimizer=f'model/chanbest_opt.pkl', f_history=f'model/chanbest_history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block finds the accuracy, f1 score and roc auc of the valid/test set\n",
    "pred_labels=classifier.predict(eval_x)\n",
    "auc=roc_auc_score(test_y,classifier.predict_proba(eval_x)[:,1])\n",
    "accuracy=np.mean(pred_labels==test_y)\n",
    "tp=np.sum(pred_labels*test_y)\n",
    "precision=tp/np.sum(pred_labels)\n",
    "recall=tp/np.sum(test_y)\n",
    "f1=2*precision*recall/(precision+recall)\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Accuracy:{accuracy}\")\n",
    "print(f\"F1-Score:{f1}\")\n",
    "print(f\"roc_auc score:{auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
