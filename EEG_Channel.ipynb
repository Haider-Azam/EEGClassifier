{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not install, you could not use those pipelines\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import elu,relu,leaky_relu\n",
    "import braindecode\n",
    "from braindecode.models import *\n",
    "from braindecode.models.functions import squeeze_final_output,square,safe_log\n",
    "from skorch.dataset import Dataset\n",
    "from skorch.callbacks import Checkpoint\n",
    "from skorch.helper import predefined_split\n",
    "from config import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from mne import set_log_level\n",
    "set_log_level(False)\n",
    "device = 'cuda' if cuda else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads preprocessed data from mat files\n",
    "import scipy\n",
    "import numpy as np\n",
    "inputs=scipy.io.loadmat(\"E:/train_set_1.mat\")\n",
    "X=inputs[\"x\"]\n",
    "y=inputs[\"y\"].squeeze()\n",
    "\n",
    "inputs=scipy.io.loadmat(\"E:/train_set_2.mat\")\n",
    "X=np.concatenate((X,inputs[\"x\"]),axis=0)\n",
    "y=np.concatenate((y,inputs[\"y\"].squeeze()),axis=0)\n",
    "input_time_length=X.shape[-1]\n",
    "inputs=scipy.io.loadmat(\"E:/test_set.mat\")\n",
    "test_x=inputs[\"x\"]\n",
    "test_y=inputs[\"y\"].squeeze()\n",
    "del inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels chosen:['F3']\n"
     ]
    }
   ],
   "source": [
    "#We will now train the model by taking pairs or combinations of channels and passing their entire length.\n",
    "ch_names=['A1', 'A2', 'C3', 'C4', 'CZ', 'F3', 'F4', 'F7', 'F8', 'FP1','FP2', 'FZ', 'O1', 'O2','P3', 'P4', 'PZ', 'T3', 'T4', 'T5', 'T6']\n",
    "picked_ch=[5]\n",
    "input_time_length=X.shape[-1]\n",
    "train_x=X[:,picked_ch]\n",
    "n_chans=len(picked_ch)\n",
    "eval_x=test_x[:,picked_ch]\n",
    "print(f'Channels chosen:{[ch_names[ch] for ch in picked_ch]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will convert the 1d array into a 2d matrix by converting from (1,60000) to (10,6000) and then passing them through the network\n",
    "#Due to conv_time_spat layer in model, it would be better to have it so that first 10 entries are in channel 1, next 10 in channel 2 etc\n",
    "#So that channel 1 will have 10,110,210 entries and so on\n",
    "n_chans=10\n",
    "input_time_length=input_time_length//n_chans\n",
    "train_x=train_x.reshape(len(train_x),n_chans,input_time_length,order='F')\n",
    "eval_x=eval_x.reshape(len(eval_x),n_chans,input_time_length,order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='shallow_deep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shallow_deep\n",
      "============================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "============================================================================================================================================\n",
      "Deep4Net (Deep4Net)                      [1, 10, 6000]             [1, 2]                    --                        --\n",
      "├─Ensure4d (ensuredims): 1-1             [1, 10, 6000]             [1, 10, 6000, 1]          --                        --\n",
      "├─Rearrange (dimshuffle): 1-2            [1, 10, 6000, 1]          [1, 1, 6000, 10]          --                        --\n",
      "├─CombinedConv (conv_time_spat): 1-3     [1, 1, 6000, 10]          [1, 32, 5976, 1]          11,072                    --\n",
      "├─BatchNorm2d (bnorm): 1-4               [1, 32, 5976, 1]          [1, 32, 5976, 1]          64                        --\n",
      "├─Expression (conv_nonlin): 1-5          [1, 32, 5976, 1]          [1, 32, 5976, 1]          --                        --\n",
      "├─AvgPool2dWithConv (pool): 1-6          [1, 32, 5976, 1]          [1, 32, 1988, 1]          --                        [15, 1]\n",
      "├─Expression (pool_nonlin): 1-7          [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
      "├─Dropout (drop_2): 1-8                  [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
      "├─Conv2d (conv_2): 1-9                   [1, 32, 1988, 1]          [1, 53, 1977, 1]          20,352                    [12, 1]\n",
      "├─BatchNorm2d (bnorm_2): 1-10            [1, 53, 1977, 1]          [1, 53, 1977, 1]          106                       --\n",
      "├─Expression (nonlin_2): 1-11            [1, 53, 1977, 1]          [1, 53, 1977, 1]          --                        --\n",
      "├─AvgPool2dWithConv (pool_2): 1-12       [1, 53, 1977, 1]          [1, 53, 655, 1]           --                        [15, 1]\n",
      "├─Expression (pool_nonlin_2): 1-13       [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
      "├─Dropout (drop_3): 1-14                 [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
      "├─Conv2d (conv_3): 1-15                  [1, 53, 655, 1]           [1, 90, 642, 1]           66,780                    [14, 1]\n",
      "├─BatchNorm2d (bnorm_3): 1-16            [1, 90, 642, 1]           [1, 90, 642, 1]           180                       --\n",
      "├─Expression (nonlin_3): 1-17            [1, 90, 642, 1]           [1, 90, 642, 1]           --                        --\n",
      "├─AvgPool2dWithConv (pool_3): 1-18       [1, 90, 642, 1]           [1, 90, 210, 1]           --                        [15, 1]\n",
      "├─Expression (pool_nonlin_3): 1-19       [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
      "├─Dropout (drop_4): 1-20                 [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
      "├─Conv2d (conv_4): 1-21                  [1, 90, 210, 1]           [1, 151, 179, 1]          434,880                   [32, 1]\n",
      "├─BatchNorm2d (bnorm_4): 1-22            [1, 151, 179, 1]          [1, 151, 179, 1]          302                       --\n",
      "├─Expression (nonlin_4): 1-23            [1, 151, 179, 1]          [1, 151, 179, 1]          --                        --\n",
      "├─AvgPool2dWithConv (pool_4): 1-24       [1, 151, 179, 1]          [1, 151, 55, 1]           --                        [15, 1]\n",
      "├─Expression (pool_nonlin_4): 1-25       [1, 151, 55, 1]           [1, 151, 55, 1]           --                        --\n",
      "├─Sequential (final_layer): 1-26         [1, 151, 55, 1]           [1, 2]                    --                        --\n",
      "│    └─Conv2d (conv_classifier): 2-1     [1, 151, 55, 1]           [1, 2, 1, 1]              16,612                    [55, 1]\n",
      "│    └─LogSoftmax (logsoftmax): 2-2      [1, 2, 1, 1]              [1, 2, 1, 1]              --                        --\n",
      "│    └─Expression (squeeze): 2-3         [1, 2, 1, 1]              [1, 2]                    --                        --\n",
      "============================================================================================================================================\n",
      "Total params: 550,348\n",
      "Trainable params: 550,348\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 160.97\n",
      "============================================================================================================================================\n",
      "Input size (MB): 0.24\n",
      "Forward/backward pass size (MB): 4.56\n",
      "Params size (MB): 2.16\n",
      "Estimated Total Size (MB): 6.96\n",
      "============================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "criterion=torch.nn.NLLLoss\n",
    "if model_name==\"shallow\":\n",
    "    optimizer_lr = 0.0000625\n",
    "    optimizer_weight_decay = 0\n",
    "    pool_time_length=150\n",
    "    pool_time_stride=50\n",
    "    #The final conv length is auto to ensure that output will give two values for single EEG window\n",
    "    model = ShallowFBCSPNet(n_chans,\n",
    "                                    n_classes,\n",
    "                                    n_filters_time=n_start_chans,\n",
    "                                    n_filters_spat=n_start_chans,\n",
    "                                    input_window_samples=input_time_length,\n",
    "                                    pool_time_length=pool_time_length,\n",
    "                                    pool_time_stride=pool_time_stride,\n",
    "                                    final_conv_length='auto',)\n",
    "    test=torch.ones(size=(7,n_chans,input_time_length))\n",
    "    out=model.forward(test)\n",
    "    print(out.shape)\n",
    "    del test,out\n",
    "elif model_name==\"deep\":\n",
    "    optimizer_lr = init_lr\n",
    "    optimizer_weight_decay = 0\n",
    "    model = Deep4Net(n_chans, n_classes,\n",
    "                         n_filters_time=n_start_chans,\n",
    "                         n_filters_spat=n_start_chans,\n",
    "                         input_window_samples=input_time_length,\n",
    "                         n_filters_2 = int(n_start_chans * n_chan_factor),\n",
    "                         n_filters_3 = int(n_start_chans * (n_chan_factor ** 2.0)),\n",
    "                         n_filters_4 = int(n_start_chans * (n_chan_factor ** 3.0)),\n",
    "                         final_conv_length='auto',\n",
    "                        stride_before_pool=True)\n",
    "    test=torch.ones(size=(7,n_chans,input_time_length))\n",
    "    out=model.forward(test)\n",
    "    print(out.shape)\n",
    "    del test,out\n",
    "elif model_name==\"deep_smac\" or model_name == 'deep_smac_bnorm':\n",
    "    optimizer_lr = 0.0000625\n",
    "    if model_name == 'deep_smac':\n",
    "            do_batch_norm = False\n",
    "    else:\n",
    "        do_batch_norm = True\n",
    "    drop_prob = 0.244445\n",
    "    filter_length_2 = 12\n",
    "    filter_length_3 = 24\n",
    "    filter_length_4 = 36\n",
    "    filter_time_length = 21\n",
    "    #final_conv_length = 1\n",
    "    first_nonlin = elu\n",
    "    first_pool_mode = 'mean'\n",
    "    later_nonlin = elu\n",
    "    later_pool_mode = 'mean'\n",
    "    n_filters_factor = 1.679066\n",
    "    n_filters_start = 32\n",
    "    pool_time_length = 3\n",
    "    pool_time_stride = 3\n",
    "    split_first_layer = True\n",
    "    n_chan_factor = n_filters_factor\n",
    "    n_start_chans = n_filters_start\n",
    "    model = Deep4Net(n_chans, n_classes,\n",
    "            n_filters_time=n_start_chans,\n",
    "            n_filters_spat=n_start_chans,\n",
    "            input_window_samples=input_time_length,\n",
    "            n_filters_2=int(n_start_chans * n_chan_factor),\n",
    "            n_filters_3=int(n_start_chans * (n_chan_factor ** 2.0)),\n",
    "            n_filters_4=int(n_start_chans * (n_chan_factor ** 3.0)),\n",
    "            final_conv_length='auto',\n",
    "            batch_norm=do_batch_norm,\n",
    "            drop_prob=drop_prob,\n",
    "            filter_length_2=filter_length_2,\n",
    "            filter_length_3=filter_length_3,\n",
    "            filter_length_4=filter_length_4,\n",
    "            filter_time_length=filter_time_length,\n",
    "            first_conv_nonlin=first_nonlin,\n",
    "            first_pool_mode=first_pool_mode,\n",
    "            later_conv_nonlin=later_nonlin,\n",
    "            later_pool_mode=later_pool_mode,\n",
    "            #pool_time_length=pool_time_length,\n",
    "            #pool_time_stride=pool_time_stride,\n",
    "            split_first_layer=split_first_layer,\n",
    "            stride_before_pool=True)\n",
    "elif model_name==\"shallow_deep\":\n",
    "    drop_prob = 0.244445\n",
    "    filter_length_2 = 12\n",
    "    filter_length_3 = 14\n",
    "    filter_length_4 = 32\n",
    "    n_filters_factor = 1.679066\n",
    "    n_filters_start = 32\n",
    "    split_first_layer = True\n",
    "    n_chan_factor = n_filters_factor\n",
    "    n_start_chans = n_filters_start\n",
    "\n",
    "    optimizer_lr = 0.0000625\n",
    "    optimizer_weight_decay = 0\n",
    "    conv_time_length=25\n",
    "    first_conv_nonlin=relu\n",
    "    first_pool_nonlin=safe_log\n",
    "    later_conv_nonlin=elu\n",
    "    later_pool_nonlin=safe_log\n",
    "    first_pool_mode = 'mean'\n",
    "    later_pool_mode = 'mean'\n",
    "    pool_time_length=15\n",
    "    model = Deep4Net(n_chans, n_classes,\n",
    "                            input_time_length,\n",
    "                            n_filters_time=n_start_chans,\n",
    "                            n_filters_spat=n_start_chans,\n",
    "                            n_filters_2 = int(n_start_chans * n_chan_factor),\n",
    "                            n_filters_3 = int(n_start_chans * (n_chan_factor ** 2.0)),\n",
    "                            n_filters_4 = int(n_start_chans * (n_chan_factor ** 3.0)),\n",
    "                            final_conv_length='auto',\n",
    "                            first_pool_nonlin=first_pool_nonlin,\n",
    "                            first_conv_nonlin=first_conv_nonlin,\n",
    "                            #later_pool_nonlin=later_pool_nonlin,\n",
    "                            #later_conv_nonlin=later_conv_nonlin,\n",
    "                            filter_time_length=conv_time_length,\n",
    "                            pool_time_length=pool_time_length,\n",
    "                            first_pool_mode=first_pool_mode,\n",
    "                            later_pool_mode=later_pool_mode,\n",
    "                            split_first_layer=split_first_layer,\n",
    "                            drop_prob=drop_prob,\n",
    "                            filter_length_2=filter_length_2,\n",
    "                            filter_length_3=filter_length_3,\n",
    "                            filter_length_4=filter_length_4,\n",
    "                            )\n",
    "elif model_name==\"attention\":\n",
    "    optimizer_lr = 0.0000625\n",
    "    optimizer_weight_decay = 0\n",
    "    model=ATCNet(n_chans,n_classes,input_time_length//sampling_freq,sampling_freq,concat=True,tcn_depth=4)\n",
    "    test=torch.ones(size=(7,n_chans,input_time_length))\n",
    "    out=model.forward(test)\n",
    "    print(out.shape)\n",
    "    del test,out\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "print(model_name)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
       "  module_=============================================================================================================================================\n",
       "  Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "  ============================================================================================================================================\n",
       "  Deep4Net (Deep4Net)                      [1, 10, 6000]             [1, 2]                    --                        --\n",
       "  ├─Ensure4d (ensuredims): 1-1             [1, 10, 6000]             [1, 10, 6000, 1]          --                        --\n",
       "  ├─Rearrange (dimshuffle): 1-2            [1, 10, 6000, 1]          [1, 1, 6000, 10]          --                        --\n",
       "  ├─CombinedConv (conv_time_spat): 1-3     [1, 1, 6000, 10]          [1, 32, 5976, 1]          11,072                    --\n",
       "  ├─BatchNorm2d (bnorm): 1-4               [1, 32, 5976, 1]          [1, 32, 5976, 1]          64                        --\n",
       "  ├─Expression (conv_nonlin): 1-5          [1, 32, 5976, 1]          [1, 32, 5976, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool): 1-6          [1, 32, 5976, 1]          [1, 32, 1988, 1]          --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin): 1-7          [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
       "  ├─Dropout (drop_2): 1-8                  [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
       "  ├─Conv2d (conv_2): 1-9                   [1, 32, 1988, 1]          [1, 53, 1977, 1]          20,352                    [12, 1]\n",
       "  ├─BatchNorm2d (bnorm_2): 1-10            [1, 53, 1977, 1]          [1, 53, 1977, 1]          106                       --\n",
       "  ├─Expression (nonlin_2): 1-11            [1, 53, 1977, 1]          [1, 53, 1977, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool_2): 1-12       [1, 53, 1977, 1]          [1, 53, 655, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_2): 1-13       [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
       "  ├─Dropout (drop_3): 1-14                 [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
       "  ├─Conv2d (conv_3): 1-15                  [1, 53, 655, 1]           [1, 90, 642, 1]           66,780                    [14, 1]\n",
       "  ├─BatchNorm2d (bnorm_3): 1-16            [1, 90, 642, 1]           [1, 90, 642, 1]           180                       --\n",
       "  ├─Expression (nonlin_3): 1-17            [1, 90, 642, 1]           [1, 90, 642, 1]           --                        --\n",
       "  ├─AvgPool2dWithConv (pool_3): 1-18       [1, 90, 642, 1]           [1, 90, 210, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_3): 1-19       [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
       "  ├─Dropout (drop_4): 1-20                 [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
       "  ├─Conv2d (conv_4): 1-21                  [1, 90, 210, 1]           [1, 151, 179, 1]          434,880                   [32, 1]\n",
       "  ├─BatchNorm2d (bnorm_4): 1-22            [1, 151, 179, 1]          [1, 151, 179, 1]          302                       --\n",
       "  ├─Expression (nonlin_4): 1-23            [1, 151, 179, 1]          [1, 151, 179, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool_4): 1-24       [1, 151, 179, 1]          [1, 151, 55, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_4): 1-25       [1, 151, 55, 1]           [1, 151, 55, 1]           --                        --\n",
       "  ├─Sequential (final_layer): 1-26         [1, 151, 55, 1]           [1, 2]                    --                        --\n",
       "  │    └─Conv2d (conv_classifier): 2-1     [1, 151, 55, 1]           [1, 2, 1, 1]              16,612                    [55, 1]\n",
       "  │    └─LogSoftmax (logsoftmax): 2-2      [1, 2, 1, 1]              [1, 2, 1, 1]              --                        --\n",
       "  │    └─Expression (squeeze): 2-3         [1, 2, 1, 1]              [1, 2]                    --                        --\n",
       "  ============================================================================================================================================\n",
       "  Total params: 550,348\n",
       "  Trainable params: 550,348\n",
       "  Non-trainable params: 0\n",
       "  Total mult-adds (M): 160.97\n",
       "  ============================================================================================================================================\n",
       "  Input size (MB): 0.24\n",
       "  Forward/backward pass size (MB): 4.56\n",
       "  Params size (MB): 2.16\n",
       "  Estimated Total Size (MB): 6.96\n",
       "  ============================================================================================================================================,\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor = lambda net: any(net.history[-1, ('valid_accuracy_best','valid_f1_best','valid_loss_best')])\n",
    "cp=Checkpoint(monitor='valid_f1_best',dirname='model',f_params=f'chanbest_param.pkl',\n",
    "               f_optimizer=f'chanbest_opt.pkl', f_history=f'chanbest_history.json')\n",
    "classifier = braindecode.EEGClassifier(\n",
    "    model,\n",
    "    criterion=criterion,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=predefined_split(Dataset(eval_x,test_y)),\n",
    "    optimizer__lr=optimizer_lr,\n",
    "    #optimizer__weight_decay=optimizer_weight_decay,\n",
    "    iterator_train__shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    "    callbacks=[\"accuracy\",\"f1\",'roc_auc',cp],#Try (\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=20))\n",
    "    warm_start=True,\n",
    "    )\n",
    "classifier.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.load_params(f_params=f'model/chanbest_param.pkl',f_optimizer=f'model/chanbest_opt.pkl', f_history=f'model/chanbest_history.json')\n",
    "print(\"Paramters Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "test=np.random.rand(7,n_chans,input_time_length)\n",
    "out=classifier.predict(test)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Accuracy    F1-score       Loss              AUC\n",
    "#A1:0.7481      0.7344        0.5478           0.8070\n",
    "#A2:0.7556      0.7130        0.6907           0.7879\n",
    "#C3:0.7259      0.7040        0.6569           0.7496\n",
    "#C4:0.7111      0.6286        0.8119           0.7738\n",
    "#CZ:0.6963      0.6306        0.7615           0.7837\n",
    "#F3:0.7111      0.6549        0.8018           0.7540\n",
    "#F4:\n",
    "#F7:\n",
    "#F8:\n",
    "#FP1:\n",
    "#FP2:\n",
    "#FZ:\n",
    "#O1:\n",
    "#O2:\n",
    "#P3:\n",
    "#P4:\n",
    "#PZ:\n",
    "#T3:\n",
    "#T4:\n",
    "#T5:\n",
    "#T6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_f1    train_loss    train_roc_auc    valid_acc    valid_accuracy    valid_f1    valid_loss    valid_roc_auc    cp     dur\n",
      "-------  ----------------  ----------  ------------  ---------------  -----------  ----------------  ----------  ------------  ---------------  ----  ------\n",
      "      1            \u001b[36m0.9581\u001b[0m      \u001b[32m0.8548\u001b[0m        \u001b[35m0.1254\u001b[0m           \u001b[31m0.9959\u001b[0m       \u001b[94m0.6370\u001b[0m            \u001b[36m0.6370\u001b[0m      \u001b[32m0.4235\u001b[0m        \u001b[35m1.3388\u001b[0m           \u001b[31m0.8118\u001b[0m     +  3.2020\n",
      "      2            \u001b[36m0.9760\u001b[0m      \u001b[32m0.9262\u001b[0m        \u001b[35m0.1063\u001b[0m           0.9949       \u001b[94m0.6963\u001b[0m            \u001b[36m0.6963\u001b[0m      \u001b[32m0.5859\u001b[0m        \u001b[35m0.9846\u001b[0m           0.7905     +  3.0500\n",
      "      3            \u001b[36m0.9844\u001b[0m      \u001b[32m0.9536\u001b[0m        0.1072           \u001b[31m0.9984\u001b[0m       0.6667            0.6667      0.5263        \u001b[35m0.9413\u001b[0m           0.7879        3.0910\n",
      "      4            0.9838      0.9486        \u001b[35m0.0912\u001b[0m           \u001b[31m0.9990\u001b[0m       0.6889            0.6889      0.5435        1.0371           \u001b[31m0.8352\u001b[0m        2.9800\n",
      "      5            0.9689      0.9113        0.0950           0.9972       0.6889            0.6889      \u001b[32m0.6038\u001b[0m        0.9649           0.7854     +  2.8470\n",
      "      6            0.9515      0.8280        0.1066           0.9961       0.6519            0.6519      0.4598        1.4015           \u001b[31m0.8354\u001b[0m        2.9280\n",
      "      7            0.9790      0.9318        0.1009           0.9986       0.6815            0.6815      0.5275        1.2847           0.8156        2.9310\n",
      "      8            0.9671      0.8884        0.0970           0.9982       0.6519            0.6519      0.4471        1.5062           0.8292        2.9440\n",
      "      9            0.6593      0.4888        0.0936           0.8973       0.5037            0.5037      0.5315        1.3846           0.5926        2.7980\n",
      "     10            0.9311      0.8228        \u001b[35m0.0901\u001b[0m           0.9906       0.6889            0.6889      0.6038        \u001b[35m0.9330\u001b[0m           0.7342        2.6180\n",
      "     11            \u001b[36m0.9946\u001b[0m      \u001b[32m0.9834\u001b[0m        0.0925           \u001b[31m0.9998\u001b[0m       0.6593            0.6593      0.5208        1.1159           0.8215        2.6340\n",
      "     12            0.9934      0.9796        0.0951           0.9997       0.6815            0.6815      0.5376        1.0974           0.8189        2.6220\n",
      "     13            0.9814      0.9400        \u001b[35m0.0852\u001b[0m           0.9992       0.6741            0.6741      0.4884        1.2807           0.8090        2.5500\n",
      "     14            0.9802      0.9364        0.0859           0.9995       0.6741            0.6741      0.5111        1.2569           \u001b[31m0.8389\u001b[0m        2.5690\n",
      "     15            0.9874      0.9602        0.0861           \u001b[31m0.9998\u001b[0m       0.6667            0.6667      0.5055        1.2255           0.8255        2.5750\n",
      "     16            0.9665      0.9064        \u001b[35m0.0823\u001b[0m           0.9965       \u001b[94m0.7111\u001b[0m            \u001b[36m0.7111\u001b[0m      \u001b[32m0.6286\u001b[0m        0.9633           0.7608     +  2.5560\n",
      "     17            \u001b[36m0.9952\u001b[0m      \u001b[32m0.9852\u001b[0m        0.0897           \u001b[31m0.9999\u001b[0m       0.6741            0.6741      0.5111        1.1489           0.8290        2.5400\n",
      "     18            0.8503      0.6762        0.0832           0.9335       0.6222            0.6222      0.5565        1.2754           0.6585        2.6320\n",
      "     19            0.9844      0.9506        \u001b[35m0.0819\u001b[0m           0.9991       0.6741            0.6741      0.5319        1.2102           \u001b[31m0.8435\u001b[0m        2.5300\n",
      "     20            0.9922      0.9757        0.0859           0.9999       0.6889            0.6889      0.5435        1.2156           0.8266        2.7600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
       "  module_=============================================================================================================================================\n",
       "  Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "  ============================================================================================================================================\n",
       "  Deep4Net (Deep4Net)                      [1, 10, 6000]             [1, 2]                    --                        --\n",
       "  ├─Ensure4d (ensuredims): 1-1             [1, 10, 6000]             [1, 10, 6000, 1]          --                        --\n",
       "  ├─Rearrange (dimshuffle): 1-2            [1, 10, 6000, 1]          [1, 1, 6000, 10]          --                        --\n",
       "  ├─CombinedConv (conv_time_spat): 1-3     [1, 1, 6000, 10]          [1, 32, 5976, 1]          11,072                    --\n",
       "  ├─BatchNorm2d (bnorm): 1-4               [1, 32, 5976, 1]          [1, 32, 5976, 1]          64                        --\n",
       "  ├─Expression (conv_nonlin): 1-5          [1, 32, 5976, 1]          [1, 32, 5976, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool): 1-6          [1, 32, 5976, 1]          [1, 32, 1988, 1]          --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin): 1-7          [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
       "  ├─Dropout (drop_2): 1-8                  [1, 32, 1988, 1]          [1, 32, 1988, 1]          --                        --\n",
       "  ├─Conv2d (conv_2): 1-9                   [1, 32, 1988, 1]          [1, 53, 1977, 1]          20,352                    [12, 1]\n",
       "  ├─BatchNorm2d (bnorm_2): 1-10            [1, 53, 1977, 1]          [1, 53, 1977, 1]          106                       --\n",
       "  ├─Expression (nonlin_2): 1-11            [1, 53, 1977, 1]          [1, 53, 1977, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool_2): 1-12       [1, 53, 1977, 1]          [1, 53, 655, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_2): 1-13       [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
       "  ├─Dropout (drop_3): 1-14                 [1, 53, 655, 1]           [1, 53, 655, 1]           --                        --\n",
       "  ├─Conv2d (conv_3): 1-15                  [1, 53, 655, 1]           [1, 90, 642, 1]           66,780                    [14, 1]\n",
       "  ├─BatchNorm2d (bnorm_3): 1-16            [1, 90, 642, 1]           [1, 90, 642, 1]           180                       --\n",
       "  ├─Expression (nonlin_3): 1-17            [1, 90, 642, 1]           [1, 90, 642, 1]           --                        --\n",
       "  ├─AvgPool2dWithConv (pool_3): 1-18       [1, 90, 642, 1]           [1, 90, 210, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_3): 1-19       [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
       "  ├─Dropout (drop_4): 1-20                 [1, 90, 210, 1]           [1, 90, 210, 1]           --                        --\n",
       "  ├─Conv2d (conv_4): 1-21                  [1, 90, 210, 1]           [1, 151, 179, 1]          434,880                   [32, 1]\n",
       "  ├─BatchNorm2d (bnorm_4): 1-22            [1, 151, 179, 1]          [1, 151, 179, 1]          302                       --\n",
       "  ├─Expression (nonlin_4): 1-23            [1, 151, 179, 1]          [1, 151, 179, 1]          --                        --\n",
       "  ├─AvgPool2dWithConv (pool_4): 1-24       [1, 151, 179, 1]          [1, 151, 55, 1]           --                        [15, 1]\n",
       "  ├─Expression (pool_nonlin_4): 1-25       [1, 151, 55, 1]           [1, 151, 55, 1]           --                        --\n",
       "  ├─Sequential (final_layer): 1-26         [1, 151, 55, 1]           [1, 2]                    --                        --\n",
       "  │    └─Conv2d (conv_classifier): 2-1     [1, 151, 55, 1]           [1, 2, 1, 1]              16,612                    [55, 1]\n",
       "  │    └─LogSoftmax (logsoftmax): 2-2      [1, 2, 1, 1]              [1, 2, 1, 1]              --                        --\n",
       "  │    └─Expression (squeeze): 2-3         [1, 2, 1, 1]              [1, 2]                    --                        --\n",
       "  ============================================================================================================================================\n",
       "  Total params: 550,348\n",
       "  Trainable params: 550,348\n",
       "  Non-trainable params: 0\n",
       "  Total mult-adds (M): 160.97\n",
       "  ============================================================================================================================================\n",
       "  Input size (MB): 0.24\n",
       "  Forward/backward pass size (MB): 4.56\n",
       "  Params size (MB): 2.16\n",
       "  Estimated Total Size (MB): 6.96\n",
       "  ============================================================================================================================================,\n",
       ")"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_x,y,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save_params(f_params=f'model/chanbest_param.pkl',f_optimizer=f'model/chanbest_opt.pkl', f_history=f'model/chanbest_history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block finds the accuracy, f1 score and roc auc of the valid/test set\n",
    "pred_labels=classifier.predict(eval_x)\n",
    "auc=roc_auc_score(test_y,classifier.predict_proba(eval_x)[:,1])\n",
    "accuracy=np.mean(pred_labels==test_y)\n",
    "tp=np.sum(pred_labels*test_y)\n",
    "precision=tp/np.sum(pred_labels)\n",
    "recall=tp/np.sum(test_y)\n",
    "f1=2*precision*recall/(precision+recall)\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Accuracy:{accuracy}\")\n",
    "print(f\"F1-Score:{f1}\")\n",
    "print(f\"roc_auc score:{auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
